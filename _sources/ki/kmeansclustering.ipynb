{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Means-Clustering\n",
    "Du kennst bereits den [k-N√§chste-Nachbarn-Algorithmus](knearestneighbor), ein Verfahren, das mit {term}`Trainingsdaten <Trainingsdaten>` neue Daten klassifiziert. Nun betrachten wir [k-Means-Clustering](https://de.wikipedia.org/wiki/k-Means-Algorithmus), einen Algorithmus, um {term}`Datenpunkte <Datenpunkt>` in sogenannte Cluster zu gruppieren.\n",
    "\n",
    "Im Bereich der KI wird oft mit gro√üen Datenmengen gearbeitet, die auf Muster untersucht und in Gruppen eingeteilt werden. Algorithmen dieser Art sind Verfahren der [Clusteranalyse](https://de.wikipedia.org/wiki/Clusteranalyse). k-Means ist so ein Algorithmus, der Datenpunkte ohne vorherige Kenntnis der Gruppenzugeh√∂rigkeit in $k$ Cluster einteilt. Das macht k-Means zu einem {term}`un√ºberwachten Lernalgorithmus <Un√ºberwachtes Lernen>`. Seine St√§rke liegt in der effizienten Strukturierung gro√üer Datens√§tze und dem Entdecken versteckter Muster.\n",
    "\n",
    "````{margin}\n",
    "```{admonition} Info\n",
    ":class: information\n",
    "[Maschinelles Lernen](https://de.wikipedia.org/wiki/Maschinelles_Lernen) ist ein Teilgebiet der KI, in dem Algorithmen aus Daten lernen und Vorhersagen oder Entscheidungen treffen k√∂nnen. Algorithmen im Bereich des maschinellen Lernens haben das Ziel, gro√üe Datenmengen zu analysieren und Muster darin zu erkennen.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √úberwachtes vs. un√ºberwachtes Lernen\n",
    "\n",
    "Beide Algorithmen stammen aus dem Bereich **Maschinelles Lernen**, welches grob in **√ºberwachtes Lernen** und **un√ºberwachtes Lernen** unterteilt wird. Beim [√ºberwachten Lernen](https://de.wikipedia.org/wiki/√úberwachtes_Lernen) wird ein Datensatz verwendet, der Trainingsdaten mit den zugeh√∂rigen **{term}`Labels <Label>`** enth√§lt. Das Modell lernt aus Beispielen, bei denen die richtigen Antworten bereits bekannt sind. Diese Methode eignet sich gut f√ºr Aufgaben wie Klassifikationen (z.B. Spam-Erkennung). Der [k-N√§chste-Nachbarn-Algorithmus](knearestneighbor) ist ein solches Verfahren.\n",
    "\n",
    "Beim [un√ºberwachten Lernen](https://de.wikipedia.org/wiki/Un√ºberwachtes_Lernen) sind die Trainingsdaten nicht gelabelt. Stattdessen versuchen un√ºberwachte Algorithmen, eigenst√§ndig Muster in den Daten zu erkennen. Clustering, wie k-Means, ist ein typisches Beispiel daf√ºr. Der Algorithmus ermittelt Gruppen (Cluster) von √§hnlichen Datenpunkten und hilft, ungeordnete Daten zu strukturieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einf√ºhrung in das Verfahren\n",
    "\n",
    "k-Means-Clustering geh√∂rt zum **un√ºberwachten Lernen**. Es gibt keine vordefinierten Labels, sondern nur die rohen Daten. Das Ziel von k-Means ist es, die Daten in **$k$ Cluster** zu unterteilen, wobei $k$ die Anzahl der Cluster darstellt. Der Algorithmus ermittelt **Zentroiden**, auch Clusterzentren genannt. Das sind die Mittelpunkte, um die sich die Cluster bilden. **Means** steht dabei f√ºr den Durchschnitt, da die Zentroiden als Durchschnitt der zugeh√∂rigen Datenpunkte im Cluster berechnet werden. Am Ende sind die Daten innerhalb eines Clusters homogener als zu den Daten in anderen Clustern.\n",
    "\n",
    "In einfachen Beispielen k√∂nnten wir die Cluster auch mit dem Auge erkennen und auch ablesen, welche Zahl f√ºr $k$ sinnvoll w√§re. Bei gro√üen Datenmengen oder nicht eindeutigen Clustern ben√∂tigen wir dann aber die Hilfe des Algorithmus.\n",
    "\n",
    "**Aufgabe 1:** Wie w√ºrdest du denn die folgenden Daten in Cluster aufteilen?\n",
    "\n",
    "```{figure} bilder/kmeans_3_cluster_einfach_datenpunkte.svg\n",
    "---\n",
    "width: 80%\n",
    "name: fig_kmeans-3-cluster-einfach-datenpunkte\n",
    "align: center\n",
    "---\n",
    "Beispiel von einfacher Verteilung von Datenpunkten\n",
    "```\n",
    "\n",
    "`````{admonition} L√∂sung\n",
    ":class: tip, dropdown\n",
    "```{figure} bilder/kmeans_3_cluster_einfach_ergebnis.svg\n",
    "---\n",
    "width: 90%\n",
    "name: fig_kmeans-3-cluster-einfach-ergebnis\n",
    "align: center\n",
    "---\n",
    "Ergebnis des k-Means-Clustering mit k=3\n",
    "```\n",
    "Es ist recht offensichtlich, dass die Datenpunkte in 3 Cluster aufgeteilt werden k√∂nnen.\n",
    "``````\n",
    "\n",
    "**Aufgabe 2:** Wenn du dir das n√§chste Beispiel anschaust: welche Cluster-Einteilung w√ºrdest du hier vornehmen?\n",
    "\n",
    "```{figure} bilder/kmeans_4_cluster_komplex_datenpunkte.svg\n",
    "---\n",
    "width: 80%\n",
    "name: fig_kmeans-3-cluster-komplex-datenpunkte\n",
    "align: center\n",
    "---\n",
    "Beispiel von komplexer Verteilung von Datenpunkten\n",
    "```\n",
    "\n",
    "``````{admonition} L√∂sung\n",
    ":class: tip, dropdown\n",
    "```{figure} bilder/kmeans_4_cluster_komplex_ergebnis.svg\n",
    "---\n",
    "width: 90%\n",
    "name: fig_kmeans-3-cluster-komplex-ergebnis\n",
    "align: center\n",
    "---\n",
    "Ergebnis des k-Means-Clustering mit k=4\n",
    "```\n",
    "Dieses Beispiel ist nicht so trivial wie das vorige. Mit blo√üem Auge lassen sich  die Cluster nicht ablesen. \n",
    "``````\n",
    "\n",
    "Mit Hilfe des k-Means-Clustering k√∂nnen die Daten also sinnvoll unterteilt werden. Aber wie macht der Algorithmus das √ºberhaupt? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(k-means-clustering-algorithmus)=\n",
    "## Der k-means-Clustering Algorithmus\n",
    "\n",
    "\n",
    "````{margin}\n",
    "```{admonition} Try it!\n",
    ":class: seealso\n",
    "Auf [dieser toll programmierten Seite](https://www.naftaliharris.com/blog/visualizing-k-means-clustering) kann man den Algorithmus mit verschiedenen Datensammlugen graphisch nachspielen!\n",
    "```\n",
    "````\n",
    "\n",
    "Der Ablauf des k-means-Clustering Algorithmus wird in folgende Schritte aufgeteilt:\n",
    "```{important}\n",
    ":name: ablauf-k-means-algorithmus\n",
    "**Auswahl der Anzahl der Cluster ($k$)**  \n",
    "Bevor der Algorithmus gestartet werden, muss die **Anzahl der Cluster** $k$ festgelegt werden. Diese Zahl bestimmt, in wie viele Gruppen die Datenpunkte aufgeteilt werden sollen.\n",
    "\n",
    "**1. Initialisierung der Zentroiden**  \n",
    "Als n√§chstes werden $k$ Datenpunkte aus den Daten oder $k$ zuf√§llige Punkte ausgew√§hlt, um die anf√§nglichen **Zentroiden** (Cluster-Zentren) zu bestimmen.\n",
    "\n",
    "**2. Zuweisung der Datenpunkte und Bildung der Cluster**  \n",
    "Jeder Datenpunkt wird dem n√§chstgelegenen Zentroiden zugewiesen. Dies wird durch die {term}`Distanzma√üe <Distanzma√üe>` zu allen Zentroiden bestimmt (z.B. mittels {term}`Euklidischer Distanz <Euklidische Distanz>` oder {term}`Manhattan-Distanz <Manhattan-Distanz>`).\n",
    "\n",
    "**3. Aktualisierung der Zentroiden**  \n",
    "Die Zentroiden werden neu berechnet, indem der Durchschnitt (**Mean**) aller Punkte innerhalb eines Clusters berechnet wird.\n",
    "\n",
    "**4. Wiederholung der Schritte 3 und 4**  \n",
    "Die Schritte 2 und 3 werden solange wiederholt, bis sich die Zentroiden nicht mehr √§ndern oder eine maximale Anzahl an Iterationen erreicht ist.\n",
    "```\n",
    "\n",
    "Versuche mal zu √ºberlegen, worin das Ziel des Algorithmus besteht? Denke dabei an die Beziehung der Datenpunkte **innerhalb** eines Clusters und Datenpunkte aus **verschiedenen** Clustern.\n",
    "\n",
    "```{admonition} L√∂sung\n",
    ":class: tip, dropdown\n",
    "Folgende Kriterien sind das Ziel:\n",
    "- Die √Ñhnlichkeit der Datenpunkte **innerhalb** der einzelnen Cluster soll **m√∂glichst hoch** sein.\n",
    "- Die √Ñhnlichkeit der Datenpunkte **zwischen** den einzelnen Clustern soll **m√∂glichst gering** sein.  \n",
    "\n",
    "Fazit: Die Datenpunkte **innerhalb** eines Cluster sollen eine **h√∂chstm√∂gliche Homogenit√§t** haben.\n",
    "```\n",
    "\n",
    "**Frage:** Warum ben√∂tigt es in der Regel mehrere Durchg√§nge (Iterationen), um die Cluster vollst√§ndig zu bilden?\n",
    "\n",
    "```{admonition} L√∂sung\n",
    ":class: tip, dropdown\n",
    "Der k-means Algorithmus braucht in der Regel mehrere Durchg√§nge, um die Cluster korrekt zu finden. Das liegt daran, dass die **Zentroiden** (also die Mittelpunkte der Cluster) anfangs **zuf√§llig gew√§hlt** werden. Am Anfang sind diese Zentroiden oft nicht optimal, da sie weit von den eigentlichen Clustern entfernt liegen k√∂nnen.\n",
    "\n",
    "In jeder Iteration passiert Folgendes:\n",
    "1. Jeder Datenpunkt wird dem n√§chstgelegenen Zentroiden zugewiesen, wodurch sich Cluster bilden oder auch √§ndern. Es ist gut m√∂glich, dass ein Datenpunkt nun in einem anderen Cluster landet. Damit √§ndert sich dann wiederum auch die Position des Zentroiden.\n",
    "2. Die Zentren werden dann neu berechnet, indem der Durchschnitt der Punkte in jeder Gruppe genommen wird.\n",
    "3. Dieser Prozess wiederholt sich: Die Datenpunkte werden immer wieder neu zugeordnet, und die Zentren verschieben sich dabei nach und nach.\n",
    "\n",
    "Das Ziel ist, dass die Zentroiden eine Position erreichen, bei der sie sich gar nicht mehr oder nicht mehr gro√ü bewegen, also eine **stabile** L√∂sung finden. Diese Stabilit√§t wird auch **Konvergenz** genannt. Je nach Anfangslage der Zentroiden kann mehrere Interationen dauern, bis der Algorithmus eine stabile Gruppierung erreicht hat. Deshalb sind mehrere Iterationen n√∂tig, um sicherzustellen, dass die Cluster gut und sinnvoll gebildet werden.\n",
    "\n",
    "Dieses iterative Verfahren f√ºhrt schlie√ülich zu einer optimalen Gruppierung der Datenpunkte, wobei jeder Punkt in dem Cluster landet, das am besten zu seinen Eigenschaften passt.\n",
    "```\n",
    "\n",
    "**Hilfreiche Quellen f√ºrs weitere Verst√§ndnis**\n",
    "- [KI Buch: Wetterdaten-Beispiel](https://www.maschinennah.de/ki-buch/)\n",
    "- [k-Means Clustering visualisiert ](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)\n",
    "- [k-Means Clustering visualisiert mit Distanzenberechnug](https://shabal.in/visuals/kmeans/6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reale Anwendungsbeispiele\n",
    "\n",
    "Welche realen Anwendungsbeispiele kannst du dir vorstellen, bei denen das k-means Clustering eingesetzt werden k√∂nnte?\n",
    "\n",
    "√úberlege dabei, in welchen Bereichen es wichtig sein k√∂nnte, Daten in Gruppen aufzuteilen, ohne dass bereits vorgegeben ist, zu welcher Gruppe ein Datenpunkt geh√∂rt. Welche Situationen kennst du, in denen Menschen, Dinge oder Objekte aufgrund ihrer √Ñhnlichkeit in Gruppen eingeteilt werden? Es gibt hier keine richtige Antwort, nur eine Auswahl an m√∂glichen Einsatzszenarien.\n",
    "\n",
    "```{admonition} Beispiele\n",
    ":class: tip, dropdown\n",
    "- *Marketing*: Kunden in verschiedene Segmente aufteilen. Dadurch k√∂nnen Unternehmen gezieltere Werbung schalten und ihre Produkte effizienter an die verschiedenen Kundengruppen anpassen.\n",
    "- *Bildanalyse*: √§hnliche Regionen in Bildern finden. Das ist besonders n√ºtzlich f√ºr die Objekterkennung. Hierbei hilft der Algorithmus, verschiedene Objekte in einem Bild zu identifizieren und zu klassifizieren.\n",
    "- *Biologie*: Forscher nutzen den Algorithmus, um √§hnliche Gene oder Spezies zu gruppieren. Dies kann helfen, neue Erkenntnisse √ºber genetische Verbindungen und Unterschiede zu gewinnen und die Evolution besser zu verstehen.\n",
    "- *Textanalyse*: Zum Beispiel kann der Algorithmus eingesetzt werden, um √§hnliche Dokumente oder Artikel zu gruppieren, was bei der Organisation gro√üer Textmengen hilfreich ist. In der Finanzwelt wird k-Means genutzt, um riskante von nicht riskanten Krediten zu unterscheiden, indem √§hnliche Kreditprofile gruppiert werden.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein konkretes Beispiel: Clustering von Obstsorten\n",
    "\n",
    "Wir m√∂chten uns ges√ºnder ern√§hren und wollen mehr Obst essen. Die WHO empfiehlt Obst mit hohen Fruchtzuckergehalt in geringen Ma√üen zu genie√üen. Obst mit einem hohen Wassergehalt f√ºhrt zu einer h√∂heren S√§ttigung. Nehmen wir an, wir haben Daten √ºber Obstsorten mit Informationen wie u.a. Wassergehalt und Fruchtzuckergehalt. Wir m√∂chten √§hnliche Obstsorten in Clustern gruppieren, sodass die Obstsorten m√∂glichst homogen sind. Anhand der Cluster k√∂nnen wir dann entscheiden, welches Obst wir in welchen Mengen essen k√∂nnen.\n",
    "\n",
    "Wir spielen dieses Beispiel mal nach und schauen uns das Ergebnis an. Die zuge√∂rigen Daten zu unseren Obstsorten sind:\n",
    "\n",
    "<small>\n",
    "\n",
    "| **Obst**       | **Wassergehalt** | **Fruchtzuckergehalt** |\n",
    "| :------------- | :--------------- | :--------------------- |\n",
    "| Apfel          | 85               | 10                     |\n",
    "| Birne          | 83               | 10                     |\n",
    "| Banane         | 75               | 12                     |\n",
    "| Orange         | 87               | 8                      |\n",
    "| Weintrauben    | 81               | 16                     |\n",
    "| Erdbeere       | 91               | 5                      |\n",
    "| Wassermelone   | 92               | 6                      |\n",
    "| Mango          | 83               | 14                     |\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Keine √ºbergro√üe Menge aber es ist schon mal nicht einfach, hier ad hoc eine konkrete Hilfestellung f√ºr unsere Obstfrage zu erhalten.\n",
    "\n",
    "In {numref}`fig_kmeans_obst` ist die Sammlung von Obstsorten visualisiert: üçé (Apfel), üçê (Birne), üçå (Banane), üçä (Orange), üçá (Weintrauben), üçì (Erdbeere), üçâ (Wassermelone), ü•≠ (Mango). Wir m√∂chten diese Obstsorten nun basierend auf Wasser- und Fruchtzuckergehalt in Cluster aufteilen.\n",
    "\n",
    "```{figure} bilder/kmeans_obst.svg\n",
    "---\n",
    "width: 80%\n",
    "name: fig_kmeans_obst\n",
    "align: center\n",
    "---\n",
    "Obstsorten visualisiert nach Wassergehalt und Fruchzuckergehalt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 1:** Wie w√ºrdest du die Obstsorten in Cluster aufteilen? √úberlege dabei, wieviele Cluster sinnvoll w√§ren, also welchen Wert $k$ einnehmen w√ºrde.\n",
    "\n",
    "```{admonition} Ergebnis k-Means\n",
    ":class: tip, dropdown\n",
    "```{figure} bilder/kmeans_obst_clusters_3.svg\n",
    "---\n",
    "width: 90%\n",
    "name: fig_kmeans_obst_3\n",
    "align: center\n",
    "---\n",
    "k-Means-Clustering der Obstsorten mit k=3\n",
    "```\n",
    "\n",
    "**Aufgabe 2:** Versuche mal, das ermittelten Cluster in eigenen Worten zusammenzufassen.\n",
    "\n",
    "```{admonition} Beschreibung des Ergebnisses\n",
    ":class: tip, dropdown\n",
    "Der Algorithmus hat die Obstsorten in 3 Cluster aufgeteilt, deren Datenpunkte die folgenden Merkmale aufweisen:\n",
    "1. üçå (Banane), üçá (Weintrauben), ü•≠ (Mango): <u>hoher bis sehr hoher</u> Fruchtzuckergehalt mit <u>mittlerem</u> Wassergehalt\n",
    "2. üçé (Apfel), üçê (Birne), üçä (Orange): <u>mittlerer</u> Fruchtzuckergehalt mit <u>hohem</u> Wassergehalt\n",
    "3. üçì (Erdbeere), üçâ (Wassermelone): <u>niedriger</u> Fruchtzuckergehalt mit sehr <u>hohem</u> Wassergehalt\n",
    "```\n",
    "\n",
    "Hast du die Einteilung von k-Means auch so √ºberlegt oder hattest du eine andere Vorstellung? Was h√§lst du denn von dieser Einteilung im Vergleich zur vorigen L√∂sung?\n",
    "\n",
    "```{admonition} Ergebnis k-Means Variante 2\n",
    ":class: tip, dropdown\n",
    "```{figure} bilder/kmeans_obst_clusters_42.svg\n",
    "---\n",
    "width: 90%\n",
    "name: fig_kmeans_obst_42\n",
    "align: center\n",
    "---\n",
    "k-Means-Clustering der Obstsorten mit k=3 Variante 2\n",
    "```\n",
    "\n",
    "√úberlege mal einen Moment, wie der Algorithmus bei gleichen Daten zu diesen unterschiedlichen Ergebnisse kommen kann.\n",
    "\n",
    "```{admonition} Tipp\n",
    ":class: tip, dropdown\n",
    "Was k√∂nnte der [Algorithmus](ablauf-k-means-algorithmus) zu Beginn anders gemacht haben, damit unterschiedliche Ergebnisse zustande kommen?\n",
    "```{admonition} Tipp, wenn du noch keine Idee hast\n",
    ":class: tip, dropdown\n",
    "Wie werden die Zentroiden initialisiert und wie kann dieses Verfahrensweise zu unterschiedliche Ergebnissen f√ºhren?\n",
    "```\n",
    "\n",
    "```{admonition} L√∂sung\n",
    ":class: tip, dropdown\n",
    "Die unterschiedlichen Ergebnisse sind eine Folge davon, dass der Algorithmus mit zuf√§lligen Startpunkten arbeitet. Je nachdem, wo die Zentroiden am Anfang liegen, teilt der Algorithmus die Punkte unterschiedlich ein. Das zeigt, dass k-Means manchmal unterschiedliche Ergebnisse liefern kann, auch wenn die Daten gleich bleiben.\n",
    "- Wenn ein Start-Zentroid mitten in einer dichten Datenmenge liegt, zieht er schnell viele Punkte an.\n",
    "- Liegt ein anderer Start-Zentroid weit weg, wird er vielleicht nur wenige Punkte anziehen.\n",
    "Der Algorithmus findet also nicht immer die 'beste' L√∂sung, sondern eine, die von den Startbedingungen abh√§ngt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisierung der Clusterzentren mit k&#8209;means++\n",
    "\n",
    "**[k-means++(https://de.wikipedia.org/wiki/K-Means-Algorithmus)]** ist eine verbesserte Methode zur Initialisierung der Clusterzentren beim k-means-Clustering. Es verbessert die Qualit√§t und Effizienz des Algorithmus durch folgende Schritte:\n",
    "\n",
    "1. **Erster Startpunkt**:\n",
    "   - Ein Punkt wird zuf√§llig aus den Daten gew√§hlt.\n",
    "2. **Gewichtete Auswahl der weitere Startpunkte**:\n",
    "   - F√ºr jeden weiteren Startpunkt wird ein Punkt basierend auf seiner Distanz zu den n√§chsten bereits gew√§hlten Startpunkten ausgew√§hlt:\n",
    "     - Punkte, die weiter entfernt sind, haben eine h√∂here Wahrscheinlichkeit, ausgew√§hlt zu werden.\n",
    "     - Die Wahrscheinlichkeit ist proportional zum Quadrat der Distanz zum n√§chsten Startpunkt ($D^2$).\n",
    "3. **Wiederhole Schritt 2**, bis $k$ Startpunkte bestimmt sind.\n",
    "4. **F√ºhre anschlie√üend das normale k-means-Verfahren durch**.\n",
    "\n",
    "**Vorteil:** Die Startpunkte werden optimal verteilt, was zu schnellerer Konvergenz und besseren Clustering-Ergebnissen f√ºhrt.\n",
    "\n",
    "```{admonition} **Wie funktioniert die gewichtete Auswahl genau?**\n",
    ":class: note\n",
    "Angenommen, es gibt 5 Punkte mit diesen Distanzen zu den bestehenden Zentren:\n",
    "\n",
    "| Punkt | Entfernung $D$ | Gewicht $D^2$ | Wahrscheinlichkeit |\n",
    "|-------|----------------|---------------|--------------------|\n",
    "| $A$   | $1$            | $1^2 = 1$     | $1 / (1 + 9 + 25 + 36 + 64) = 1/135 \\approx 0.74\\%$ |\n",
    "| $B$   | $3$            | $3^2 = 9$     | $9 / 135 \\approx 6.67\\%$ |\n",
    "| $C$   | $5$            | $5^2 = 25$    | $25 / 135 \\approx 18.52\\%$ |\n",
    "| $D$   | $6$            | $6^2 = 36$    | $36 / 135 \\approx 26.67\\%$ |\n",
    "| $E$   | $8$            | $8^2 = 64$    | $64 / 135 \\approx 47.41\\%$ |\n",
    "\n",
    "[comment]: <Abstand nach Tabelle>\n",
    "<div style=\"margin-top: 20px;\"></div>\n",
    "\n",
    "Punkt $E$ hat die gr√∂√üte Wahrscheinlichkeit, gew√§hlt zu werden, aber nicht zu 100%. Es kann jedoch auch jeder andere Punkt gew√§hlt werden, abh√§ngig von seiner Wahrscheinlichkeit.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein Beispiel zum Nachrechnen\n",
    "\n",
    "Du wei√üt nun, wie der Algorithmus funktioniert und zu welchen Ergebnissen er f√ºhren kann. Am besten kannst du das nachvollziehen, indem du den Algorithmus selbst mal durchf√ºhrst. Lade dir dieses\n",
    "{download}`Aufgabenblatt <kmeansclustering_aufgabenblatt.pdf>` herunter und bearbeite es. Die Anweisungen findest du dem Arbeitsblatt. Viel Erfolg üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die richtige Wahl f√ºr $k$ mit der Elbow-Methode\n",
    "\n",
    "Bisher haben wir f√ºr unsere Beispiele $k$ so gew√§hlt, dass es dem Verst√§ndnis passte. Doch in der Praxis stellt sich oft die Frage: **Wie w√§hle ich die optimale Anzahl von $k$ Clustern ?**\n",
    "\n",
    "Hier kommt die **Elbow-Methode** ins Spiel. Sie hilft uns, auf systematische Weise die Anzahl der Cluster zu bestimmen, die sowohl eine gute Datenaufteilung gew√§hrleistet als auch unn√∂tig viele Cluster vermeidet.\n",
    "\n",
    "Die Idee der Methode ist wie folgt:  \n",
    "- Wir berechnen die sogenannte **Tr√§gheit** (Summe der Abst√§nde der Datenpunkte zu ihren Clusterzentren) f√ºr verschiedene Werte von $k$.  \n",
    "- Die Tr√§gheit nimmt mit steigender Clusteranzahl $k$ ab, weil mehr Cluster zu kleineren Distanzen f√ºhren.  \n",
    "- Jedoch flacht die Abnahme ab, und ab einem bestimmten Punkt lohnt es sich nicht mehr, die Anzahl der Cluster weiter zu erh√∂hen. Dieser Punkt wird als **Knickpunkt (Elbow)** bezeichnet.\n",
    "\n",
    "```{figure} bilder/kmeans_elbow_demo.svg\n",
    "---\n",
    "width: 90%\n",
    "name: fig_kmeans_elbow_demo.svg\n",
    "align: center\n",
    "---\n",
    "Demonstration der Elbow-Methode\n",
    "```\n",
    "\n",
    "Die optimale Anzahl der Cluster $k$ ist genau dort, wo dieser Knickpunkt liegt. Dies ist der Punkt, an dem die Verbesserung durch mehr Cluster stark nachl√§sst, und wir eine gute Balance zwischen Genauigkeit und Einfachheit erreichen.\n",
    "\n",
    "```{admonition} Warum funktioniert die Elbow-Methode?\n",
    ":class: note\n",
    "Die Methode basiert auf der Idee, dass eine kleine Anzahl von Clustern zu einer schlechten Gruppierung f√ºhrt, w√§hrend eine zu gro√üe Anzahl von Clustern unn√∂tig ist und zu [Overfitting](overfitting) f√ºhren kann. Der Knick bei Anzahl der Cluster $= 2$ zeigt den Punkt, an dem sich der Aufwand f√ºr mehr Cluster nicht mehr lohnt.\n",
    "```\n",
    "\n",
    "Mit der Elbow-Methode k√∂nnen wir also datengetrieben und anschaulich entscheiden, wie viele Cluster sinnvoll sind, anstatt dies nur durch Intuition oder Versuch und Irrtum zu bestimmen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

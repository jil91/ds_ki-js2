
<!DOCTYPE html>


<html lang="de" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>22. k-Means-Clustering &#8212; Datenstrukturen und KI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/thebe.css?v=9bca0c2f" />
    <link rel="stylesheet" type="text/css" href="../_static/code.css?v=4bf7ba55" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy_custom.css?v=eb815f20" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=91fba89f"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=79cc9f76"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script defer="defer" src="../_static/refresh.js?v=9bea9b76"></script>
    <script>const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script defer="defer" src="../_static/sphinx-thebe-lite.js?v=2a71eeb1"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script defer="defer" src="../_static/tippy/ki/kmeansclustering.17584432-39b5-4225-b559-4bb44cdb7a4f.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ki/kmeansclustering';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/dropdown-opener.js?v=628c8bad"></script>
    <link rel="canonical" href="¬†&#34;https://jil91.github.io/&#34;/ki/kmeansclustering.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Stichwortverzeichnis" href="../genindex.html" />
    <link rel="search" title="Suche" href="../search.html" />
    <link rel="next" title="22.8. Programmierung des Algorithmus" href="kmeansclustering2_aufgabe.html" />
    <link rel="prev" title="21.6. Eigenschaften und Varianten des k-N√§chste-Nachbarn-Algorithmus" href="knearestneighbor2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="de"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Datenstrukturen und KI</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Suche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Nutzung</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../nutzung.html">1. Wie nutzt du dieses Buch am besten?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../live_code.html">1.3. Programmieren direkt in diesem Buch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../parsons_problems_einfuehrung.html">1.4. Parsons-Probleme</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Objektorienterte Programmierung (OOP)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../oop/t01_einstieg.html">2. Einf√ºhrung in OOP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t02_kapselung.html">3. Datenkapselung</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t03_vererbung.html">4. Vererbung</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t05_interfaces.html">5. Interfaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t06_klassenvariablen.html">6. Klassenvariablen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t07_assoziationen.html">7. Assoziationen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t08_3SA.html">8. 3SA - Drei-Schichten-Architektur</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t09_sequenzdiagramme.html">9. Sequenzdiagramme</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datenbanken</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../db/t10_einstieg_db.html">10. Einstieg Datenbanken</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t11_erm.html">11. Entity-Relationship-Modell (ERM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t12_erm_rm.html">12. Vom ERM ins Relationale Modell (RM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t13_normalisierung.html">13. Normalisierung</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datenstrukturen</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/datenstrukturen_allgemein.html">14. Abstrakte Datentypen (ADT) vs Datenstrukturen</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/listen_einfuehrung.html">15. Listen</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_listen.html">15.2. Verkettete Listen</a></li>

<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen1.html">15.4. Operationen f√ºr verkettete Listen implementieren (Teil 1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen2.html">15.5. Operationen f√ºr verkettete Listen implementieren (Teil 2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen_loesungen.html">15.6. L√∂sungen: Operationen f√ºr verkettete Listen implementieren</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/stapel_und_warteschlangen_intro.html">16. Stapel und Warteschlangen</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/stack.html">16.1. Stapel (Stack)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/stack-aufgaben.html">16.2. √úbungen zu Stapeln</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/warteschlangen.html">16.3. Warteschlangen</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/assoziative_arrays.html">17. Assoziative Arrays</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/baeume.html">18. B√§ume</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/binaerbaeume.html">18.4. Bin√§rb√§ume</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/suchbaeume.html">18.5. Bin√§re Suchb√§ume</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/klausurvorbereitung_mit_loesungen.html">19. Aufgaben zur Vorbereitung auf Klausur und Abitur</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">K√ºnstliche Intelligenz</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ki_allgemein.html">20. K√ºnstliche Intelligenz: Einf√ºhrung</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="knearestneighbor.html">21. Der k-N√§chste-Nachbarn-Algorithmus</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="knearestneighbor2.html">21.6. Eigenschaften und Varianten des k-N√§chste-Nachbarn-Algorithmus</a></li>

</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">22. k-Means-Clustering</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="kmeansclustering2_aufgabe.html">22.8. Programmierung des Algorithmus</a></li>
<li class="toctree-l2"><a class="reference internal" href="kmeansclustering2_loesung.html">22.9. Programmierung des Algorithmus (L√∂sung)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="entscheidungsbaumlernen.html">23. Entscheidungsb√§ume lernen</a></li>
<li class="toctree-l1"><a class="reference internal" href="minimax.html">24. Der Minimax-Algorithmus</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>



<a href="https://github.com/jil91/ds_ki-js2" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Quell-Repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Laden Sie diese Seite herunter">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/ki/kmeansclustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Quelldatei herunterladen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="In PDF drucken"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Vollbildmodus"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>k-Means-Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Inhalt </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uberwachtes-vs-unuberwachtes-lernen">22.1. √úberwachtes vs. un√ºberwachtes Lernen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einfuhrung-in-das-verfahren">22.2. Einf√ºhrung in das Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#der-k-means-clustering-algorithmus">22.3. Der k-means-Clustering Algorithmus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reale-anwendungsbeispiele">22.4. Reale Anwendungsbeispiele</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-konkretes-beispiel-clustering-von-obstsorten">22.5. Ein konkretes Beispiel: Clustering von Obstsorten</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisierung-der-clusterzentren-mit-kmeans">22.5.1. Initialisierung der Clusterzentren mit k‚Äëmeans++</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-beispiel-zum-nachrechnen">22.6. Ein Beispiel zum Nachrechnen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode">22.7. Die richtige Wahl f√ºr <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="k-means-clustering">
<h1><span class="section-number">22. </span>k-Means-Clustering<a class="headerlink" href="#k-means-clustering" title="Link to this heading">#</a></h1>
<p>Du kennst bereits den <a class="reference internal" href="knearestneighbor.html"><span class="doc std std-doc">k-N√§chste-Nachbarn-Algorithmus</span></a>, ein Verfahren, das mit <a class="reference internal" href="ki_allgemein.html#term-Trainingsdaten"><span class="xref std std-term">Trainingsdaten</span></a> neue Daten klassifiziert. Nun betrachten wir <a class="reference external" href="https://de.wikipedia.org/wiki/k-Means-Algorithmus">k-Means-Clustering</a>, einen Algorithmus, um <a class="reference internal" href="ki_allgemein.html#term-Datenpunkt"><span class="xref std std-term">Datenpunkte</span></a> in sogenannte Cluster zu gruppieren.</p>
<p>Im Bereich der KI wird oft mit gro√üen Datenmengen gearbeitet, die auf Muster untersucht und in Gruppen eingeteilt werden. Algorithmen dieser Art sind Verfahren der <a class="reference external" href="https://de.wikipedia.org/wiki/Clusteranalyse">Clusteranalyse</a>. k-Means ist so ein Algorithmus, der Datenpunkte ohne vorherige Kenntnis der Gruppenzugeh√∂rigkeit in <span class="math notranslate nohighlight">\(k\)</span> Cluster einteilt. Das macht k-Means zu einem <a class="reference internal" href="ki_allgemein.html#term-Unuberwachtes-Lernen"><span class="xref std std-term">un√ºberwachten Lernalgorithmus</span></a>. Seine St√§rke liegt in der effizienten Strukturierung gro√üer Datens√§tze und dem Entdecken versteckter Muster.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="information admonition">
<p class="admonition-title">Info</p>
<p><a class="reference external" href="https://de.wikipedia.org/wiki/Maschinelles_Lernen">Maschinelles Lernen</a> ist ein Teilgebiet der KI, in dem Algorithmen aus Daten lernen und Vorhersagen oder Entscheidungen treffen k√∂nnen. Algorithmen im Bereich des maschinellen Lernens haben das Ziel, gro√üe Datenmengen zu analysieren und Muster darin zu erkennen.</p>
</div>
</aside>
<section id="uberwachtes-vs-unuberwachtes-lernen">
<h2><span class="section-number">22.1. </span>√úberwachtes vs. un√ºberwachtes Lernen<a class="headerlink" href="#uberwachtes-vs-unuberwachtes-lernen" title="Link to this heading">#</a></h2>
<p>Beide Algorithmen stammen aus dem Bereich <strong>Maschinelles Lernen</strong>, welches grob in <strong>√ºberwachtes Lernen</strong> und <strong>un√ºberwachtes Lernen</strong> unterteilt wird. Beim <a class="reference external" href="https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen">√ºberwachten Lernen</a> wird ein Datensatz verwendet, der Trainingsdaten mit den zugeh√∂rigen <strong><a class="reference internal" href="ki_allgemein.html#term-Label"><span class="xref std std-term">Labels</span></a></strong> enth√§lt. Das Modell lernt aus Beispielen, bei denen die richtigen Antworten bereits bekannt sind. Diese Methode eignet sich gut f√ºr Aufgaben wie Klassifikationen (z.B. Spam-Erkennung). Der <a class="reference internal" href="knearestneighbor.html"><span class="doc std std-doc">k-N√§chste-Nachbarn-Algorithmus</span></a> ist ein solches Verfahren.</p>
<p>Beim <a class="reference external" href="https://de.wikipedia.org/wiki/Un%C3%BCberwachtes_Lernen">un√ºberwachten Lernen</a> sind die Trainingsdaten nicht gelabelt. Stattdessen versuchen un√ºberwachte Algorithmen, eigenst√§ndig Muster in den Daten zu erkennen. Clustering, wie k-Means, ist ein typisches Beispiel daf√ºr. Der Algorithmus ermittelt Gruppen (Cluster) von √§hnlichen Datenpunkten und hilft, ungeordnete Daten zu strukturieren.</p>
</section>
<section id="einfuhrung-in-das-verfahren">
<h2><span class="section-number">22.2. </span>Einf√ºhrung in das Verfahren<a class="headerlink" href="#einfuhrung-in-das-verfahren" title="Link to this heading">#</a></h2>
<p>k-Means-Clustering geh√∂rt zum <strong>un√ºberwachten Lernen</strong>. Es gibt keine vordefinierten Labels, sondern nur die rohen Daten. Das Ziel von k-Means ist es, die Daten in <strong><span class="math notranslate nohighlight">\(k\)</span> Cluster</strong> zu unterteilen, wobei <span class="math notranslate nohighlight">\(k\)</span> die Anzahl der Cluster darstellt. Der Algorithmus ermittelt <strong>Zentroiden</strong>, auch Clusterzentren genannt. Das sind die Mittelpunkte, um die sich die Cluster bilden. <strong>Means</strong> steht dabei f√ºr den Durchschnitt, da die Zentroiden als Durchschnitt der zugeh√∂rigen Datenpunkte im Cluster berechnet werden. Am Ende sind die Daten innerhalb eines Clusters homogener als zu den Daten in anderen Clustern.</p>
<p>In einfachen Beispielen k√∂nnten wir die Cluster auch mit dem Auge erkennen und auch ablesen, welche Zahl f√ºr <span class="math notranslate nohighlight">\(k\)</span> sinnvoll w√§re. Bei gro√üen Datenmengen oder nicht eindeutigen Clustern ben√∂tigen wir dann aber die Hilfe des Algorithmus.</p>
<p><strong>Aufgabe 1:</strong> Wie w√ºrdest du denn die folgenden Daten in Cluster aufteilen?</p>
<figure class="align-center" id="fig-kmeans-3-cluster-einfach-datenpunkte">
<a class="reference internal image-reference" href="../_images/kmeans_3_cluster_einfach_datenpunkte.svg"><img alt="../_images/kmeans_3_cluster_einfach_datenpunkte.svg" src="../_images/kmeans_3_cluster_einfach_datenpunkte.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.1 </span><span class="caption-text">Beispiel von einfacher Verteilung von Datenpunkten</span><a class="headerlink" href="#fig-kmeans-3-cluster-einfach-datenpunkte" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip dropdown admonition">
<p class="admonition-title">L√∂sung</p>
<figure class="align-center" id="fig-kmeans-3-cluster-einfach-ergebnis">
<a class="reference internal image-reference" href="../_images/kmeans_3_cluster_einfach_ergebnis.svg"><img alt="../_images/kmeans_3_cluster_einfach_ergebnis.svg" src="../_images/kmeans_3_cluster_einfach_ergebnis.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.2 </span><span class="caption-text">Ergebnis des k-Means-Clustering mit k=3</span><a class="headerlink" href="#fig-kmeans-3-cluster-einfach-ergebnis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Es ist recht offensichtlich, dass die Datenpunkte in 3 Cluster aufgeteilt werden k√∂nnen.</p>
</div>
<p><strong>Aufgabe 2:</strong> Wenn du dir das n√§chste Beispiel anschaust: welche Cluster-Einteilung w√ºrdest du hier vornehmen?</p>
<figure class="align-center" id="fig-kmeans-3-cluster-komplex-datenpunkte">
<a class="reference internal image-reference" href="../_images/kmeans_4_cluster_komplex_datenpunkte.svg"><img alt="../_images/kmeans_4_cluster_komplex_datenpunkte.svg" src="../_images/kmeans_4_cluster_komplex_datenpunkte.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.3 </span><span class="caption-text">Beispiel von komplexer Verteilung von Datenpunkten</span><a class="headerlink" href="#fig-kmeans-3-cluster-komplex-datenpunkte" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip dropdown admonition">
<p class="admonition-title">L√∂sung</p>
<figure class="align-center" id="fig-kmeans-3-cluster-komplex-ergebnis">
<a class="reference internal image-reference" href="../_images/kmeans_4_cluster_komplex_ergebnis.svg"><img alt="../_images/kmeans_4_cluster_komplex_ergebnis.svg" src="../_images/kmeans_4_cluster_komplex_ergebnis.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.4 </span><span class="caption-text">Ergebnis des k-Means-Clustering mit k=4</span><a class="headerlink" href="#fig-kmeans-3-cluster-komplex-ergebnis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Dieses Beispiel ist nicht so trivial wie das vorige. Mit blo√üem Auge lassen sich  die Cluster nicht ablesen.</p>
</div>
<p>Mit Hilfe des k-Means-Clustering k√∂nnen die Daten also sinnvoll unterteilt werden. Aber wie macht der Algorithmus das √ºberhaupt? ü§î</p>
</section>
<section id="der-k-means-clustering-algorithmus">
<span id="k-means-clustering-algorithmus"></span><h2><span class="section-number">22.3. </span>Der k-means-Clustering Algorithmus<a class="headerlink" href="#der-k-means-clustering-algorithmus" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="seealso admonition">
<p class="admonition-title">Try it!</p>
<p>Auf <a class="reference external" href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering">dieser toll programmierten Seite</a> kann man den Algorithmus mit verschiedenen Datensammlugen graphisch nachspielen!</p>
</div>
</aside>
<p>Der Ablauf des k-means-Clustering Algorithmus wird in folgende Schritte aufgeteilt:</p>
<div class="admonition important" id="ablauf-k-means-algorithmus">
<p class="admonition-title">Wichtig</p>
<p><strong>Auswahl der Anzahl der Cluster (<span class="math notranslate nohighlight">\(k\)</span>)</strong><br />
Bevor der Algorithmus gestartet werden, muss die <strong>Anzahl der Cluster</strong> <span class="math notranslate nohighlight">\(k\)</span> festgelegt werden. Diese Zahl bestimmt, in wie viele Gruppen die Datenpunkte aufgeteilt werden sollen.</p>
<p><strong>1. Initialisierung der Zentroiden</strong><br />
Als n√§chstes werden <span class="math notranslate nohighlight">\(k\)</span> Datenpunkte aus den Daten oder <span class="math notranslate nohighlight">\(k\)</span> zuf√§llige Punkte ausgew√§hlt, um die anf√§nglichen <strong>Zentroiden</strong> (Cluster-Zentren) zu bestimmen.</p>
<p><strong>2. Zuweisung der Datenpunkte und Bildung der Cluster</strong><br />
Jeder Datenpunkt wird dem n√§chstgelegenen Zentroiden zugewiesen. Dies wird durch die <a class="reference internal" href="ki_allgemein.html#term-Distanzmasze"><span class="xref std std-term">Distanzma√üe</span></a> zu allen Zentroiden bestimmt (z.B. mittels <a class="reference internal" href="ki_allgemein.html#term-Euklidische-Distanz"><span class="xref std std-term">Euklidischer Distanz</span></a> oder <a class="reference internal" href="ki_allgemein.html#term-Manhattan-Distanz"><span class="xref std std-term">Manhattan-Distanz</span></a>).</p>
<p><strong>3. Aktualisierung der Zentroiden</strong><br />
Die Zentroiden werden neu berechnet, indem der Durchschnitt (<strong>Mean</strong>) aller Punkte innerhalb eines Clusters berechnet wird.</p>
<p><strong>4. Wiederholung der Schritte 3 und 4</strong><br />
Die Schritte 2 und 3 werden solange wiederholt, bis sich die Zentroiden nicht mehr √§ndern oder eine maximale Anzahl an Iterationen erreicht ist.</p>
</div>
<p>Versuche mal zu √ºberlegen, worin das Ziel des Algorithmus besteht? Denke dabei an die Beziehung der Datenpunkte <strong>innerhalb</strong> eines Clusters und Datenpunkte aus <strong>verschiedenen</strong> Clustern.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">L√∂sung</p>
<p>Folgende Kriterien sind das Ziel:</p>
<ul class="simple">
<li><p>Die √Ñhnlichkeit der Datenpunkte <strong>innerhalb</strong> der einzelnen Cluster soll <strong>m√∂glichst hoch</strong> sein.</p></li>
<li><p>Die √Ñhnlichkeit der Datenpunkte <strong>zwischen</strong> den einzelnen Clustern soll <strong>m√∂glichst gering</strong> sein.</p></li>
</ul>
<p>Fazit: Die Datenpunkte <strong>innerhalb</strong> eines Cluster sollen eine <strong>h√∂chstm√∂gliche Homogenit√§t</strong> haben.</p>
</div>
<p><strong>Frage:</strong> Warum ben√∂tigt es in der Regel mehrere Durchg√§nge (Iterationen), um die Cluster vollst√§ndig zu bilden?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">L√∂sung</p>
<p>Der k-means Algorithmus braucht in der Regel mehrere Durchg√§nge, um die Cluster korrekt zu finden. Das liegt daran, dass die <strong>Zentroiden</strong> (also die Mittelpunkte der Cluster) anfangs <strong>zuf√§llig gew√§hlt</strong> werden. Am Anfang sind diese Zentroiden oft nicht optimal, da sie weit von den eigentlichen Clustern entfernt liegen k√∂nnen.</p>
<p>In jeder Iteration passiert Folgendes:</p>
<ol class="arabic simple">
<li><p>Jeder Datenpunkt wird dem n√§chstgelegenen Zentroiden zugewiesen, wodurch sich Cluster bilden oder auch √§ndern. Es ist gut m√∂glich, dass ein Datenpunkt nun in einem anderen Cluster landet. Damit √§ndert sich dann wiederum auch die Position des Zentroiden.</p></li>
<li><p>Die Zentren werden dann neu berechnet, indem der Durchschnitt der Punkte in jeder Gruppe genommen wird.</p></li>
<li><p>Dieser Prozess wiederholt sich: Die Datenpunkte werden immer wieder neu zugeordnet, und die Zentren verschieben sich dabei nach und nach.</p></li>
</ol>
<p>Das Ziel ist, dass die Zentroiden eine Position erreichen, bei der sie sich gar nicht mehr oder nicht mehr gro√ü bewegen, also eine <strong>stabile</strong> L√∂sung finden. Diese Stabilit√§t wird auch <strong>Konvergenz</strong> genannt. Je nach Anfangslage der Zentroiden kann mehrere Interationen dauern, bis der Algorithmus eine stabile Gruppierung erreicht hat. Deshalb sind mehrere Iterationen n√∂tig, um sicherzustellen, dass die Cluster gut und sinnvoll gebildet werden.</p>
<p>Dieses iterative Verfahren f√ºhrt schlie√ülich zu einer optimalen Gruppierung der Datenpunkte, wobei jeder Punkt in dem Cluster landet, das am besten zu seinen Eigenschaften passt.</p>
</div>
<p><strong>Hilfreiche Quellen f√ºrs weitere Verst√§ndnis</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.maschinennah.de/ki-buch/">KI Buch: Wetterdaten-Beispiel</a></p></li>
<li><p><a class="reference external" href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">k-Means Clustering visualisiert </a></p></li>
<li><p><a class="reference external" href="https://shabal.in/visuals/kmeans/6.html">k-Means Clustering visualisiert mit Distanzenberechnug</a></p></li>
</ul>
</section>
<section id="reale-anwendungsbeispiele">
<h2><span class="section-number">22.4. </span>Reale Anwendungsbeispiele<a class="headerlink" href="#reale-anwendungsbeispiele" title="Link to this heading">#</a></h2>
<p>Welche realen Anwendungsbeispiele kannst du dir vorstellen, bei denen das k-means Clustering eingesetzt werden k√∂nnte?</p>
<p>√úberlege dabei, in welchen Bereichen es wichtig sein k√∂nnte, Daten in Gruppen aufzuteilen, ohne dass bereits vorgegeben ist, zu welcher Gruppe ein Datenpunkt geh√∂rt. Welche Situationen kennst du, in denen Menschen, Dinge oder Objekte aufgrund ihrer √Ñhnlichkeit in Gruppen eingeteilt werden? Es gibt hier keine richtige Antwort, nur eine Auswahl an m√∂glichen Einsatzszenarien.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Beispiele</p>
<ul class="simple">
<li><p><em>Marketing</em>: Kunden in verschiedene Segmente aufteilen. Dadurch k√∂nnen Unternehmen gezieltere Werbung schalten und ihre Produkte effizienter an die verschiedenen Kundengruppen anpassen.</p></li>
<li><p><em>Bildanalyse</em>: √§hnliche Regionen in Bildern finden. Das ist besonders n√ºtzlich f√ºr die Objekterkennung. Hierbei hilft der Algorithmus, verschiedene Objekte in einem Bild zu identifizieren und zu klassifizieren.</p></li>
<li><p><em>Biologie</em>: Forscher nutzen den Algorithmus, um √§hnliche Gene oder Spezies zu gruppieren. Dies kann helfen, neue Erkenntnisse √ºber genetische Verbindungen und Unterschiede zu gewinnen und die Evolution besser zu verstehen.</p></li>
<li><p><em>Textanalyse</em>: Zum Beispiel kann der Algorithmus eingesetzt werden, um √§hnliche Dokumente oder Artikel zu gruppieren, was bei der Organisation gro√üer Textmengen hilfreich ist. In der Finanzwelt wird k-Means genutzt, um riskante von nicht riskanten Krediten zu unterscheiden, indem √§hnliche Kreditprofile gruppiert werden.</p></li>
</ul>
</div>
</section>
<section id="ein-konkretes-beispiel-clustering-von-obstsorten">
<h2><span class="section-number">22.5. </span>Ein konkretes Beispiel: Clustering von Obstsorten<a class="headerlink" href="#ein-konkretes-beispiel-clustering-von-obstsorten" title="Link to this heading">#</a></h2>
<p>Wir m√∂chten uns ges√ºnder ern√§hren und wollen mehr Obst essen. Die WHO empfiehlt Obst mit hohen Fruchtzuckergehalt in geringen Ma√üen zu genie√üen. Obst mit einem hohen Wassergehalt f√ºhrt zu einer h√∂heren S√§ttigung. Nehmen wir an, wir haben Daten √ºber Obstsorten mit Informationen wie u.a. Wassergehalt und Fruchtzuckergehalt. Wir m√∂chten √§hnliche Obstsorten in Clustern gruppieren, sodass die Obstsorten m√∂glichst homogen sind. Anhand der Cluster k√∂nnen wir dann entscheiden, welches Obst wir in welchen Mengen essen k√∂nnen.</p>
<p>Wir spielen dieses Beispiel mal nach und schauen uns das Ergebnis an. Die zuge√∂rigen Daten zu unseren Obstsorten sind:</p>
<small>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Obst</strong></p></th>
<th class="head text-left"><p><strong>Wassergehalt</strong></p></th>
<th class="head text-left"><p><strong>Fruchtzuckergehalt</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Apfel</p></td>
<td class="text-left"><p>85</p></td>
<td class="text-left"><p>10</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Birne</p></td>
<td class="text-left"><p>83</p></td>
<td class="text-left"><p>10</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Banane</p></td>
<td class="text-left"><p>75</p></td>
<td class="text-left"><p>12</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Orange</p></td>
<td class="text-left"><p>87</p></td>
<td class="text-left"><p>8</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Weintrauben</p></td>
<td class="text-left"><p>81</p></td>
<td class="text-left"><p>16</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Erdbeere</p></td>
<td class="text-left"><p>91</p></td>
<td class="text-left"><p>5</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Wassermelone</p></td>
<td class="text-left"><p>92</p></td>
<td class="text-left"><p>6</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Mango</p></td>
<td class="text-left"><p>83</p></td>
<td class="text-left"><p>14</p></td>
</tr>
</tbody>
</table>
</div>
</small><p>Keine √ºbergro√üe Menge aber es ist schon mal nicht einfach, hier ad hoc eine konkrete Hilfestellung f√ºr unsere Obstfrage zu erhalten.</p>
<p>In <a class="reference internal" href="#fig-kmeans-obst"><span class="std std-numref">Abb. 22.5</span></a> ist die Sammlung von Obstsorten visualisiert: üçé (Apfel), üçê (Birne), üçå (Banane), üçä (Orange), üçá (Weintrauben), üçì (Erdbeere), üçâ (Wassermelone), ü•≠ (Mango). Wir m√∂chten diese Obstsorten nun basierend auf Wasser- und Fruchtzuckergehalt in Cluster aufteilen.</p>
<figure class="align-center" id="fig-kmeans-obst">
<a class="reference internal image-reference" href="../_images/kmeans_obst.svg"><img alt="../_images/kmeans_obst.svg" src="../_images/kmeans_obst.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.5 </span><span class="caption-text">Obstsorten visualisiert nach Wassergehalt und Fruchzuckergehalt</span><a class="headerlink" href="#fig-kmeans-obst" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Aufgabe 1:</strong> Wie w√ºrdest du die Obstsorten in Cluster aufteilen? √úberlege dabei, wieviele Cluster sinnvoll w√§ren, also welchen Wert <span class="math notranslate nohighlight">\(k\)</span> einnehmen w√ºrde.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Ergebnis k-Means</p>
<figure class="align-center" id="fig-kmeans-obst-3">
<a class="reference internal image-reference" href="../_images/kmeans_obst_clusters_3.svg"><img alt="../_images/kmeans_obst_clusters_3.svg" src="../_images/kmeans_obst_clusters_3.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.6 </span><span class="caption-text">k-Means-Clustering der Obstsorten mit k=3</span><a class="headerlink" href="#fig-kmeans-obst-3" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
<p><strong>Aufgabe 2:</strong> Versuche mal, das ermittelten Cluster in eigenen Worten zusammenzufassen.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Beschreibung des Ergebnisses</p>
<p>Der Algorithmus hat die Obstsorten in 3 Cluster aufgeteilt, deren Datenpunkte die folgenden Merkmale aufweisen:</p>
<ol class="arabic simple">
<li><p>üçå (Banane), üçá (Weintrauben), ü•≠ (Mango): <u>hoher bis sehr hoher</u> Fruchtzuckergehalt mit <u>mittlerem</u> Wassergehalt</p></li>
<li><p>üçé (Apfel), üçê (Birne), üçä (Orange): <u>mittlerer</u> Fruchtzuckergehalt mit <u>hohem</u> Wassergehalt</p></li>
<li><p>üçì (Erdbeere), üçâ (Wassermelone): <u>niedriger</u> Fruchtzuckergehalt mit sehr <u>hohem</u> Wassergehalt</p></li>
</ol>
</div>
<p>Hast du die Einteilung von k-Means auch so √ºberlegt oder hattest du eine andere Vorstellung? Was h√§lst du denn von dieser Einteilung im Vergleich zur vorigen L√∂sung?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Ergebnis k-Means Variante 2</p>
<figure class="align-center" id="fig-kmeans-obst-42">
<a class="reference internal image-reference" href="../_images/kmeans_obst_clusters_42.svg"><img alt="../_images/kmeans_obst_clusters_42.svg" src="../_images/kmeans_obst_clusters_42.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.7 </span><span class="caption-text">k-Means-Clustering der Obstsorten mit k=3 Variante 2</span><a class="headerlink" href="#fig-kmeans-obst-42" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
<p>√úberlege mal einen Moment, wie der Algorithmus bei gleichen Daten zu diesen unterschiedlichen Ergebnisse kommen kann.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Tipp</p>
<p>Was k√∂nnte der <a class="reference internal" href="#ablauf-k-means-algorithmus"><span class="std std-ref">Algorithmus</span></a> zu Beginn anders gemacht haben, damit unterschiedliche Ergebnisse zustande kommen?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Tipp, wenn du noch keine Idee hast</p>
<p>Wie werden die Zentroiden initialisiert und wie kann dieses Verfahrensweise zu unterschiedliche Ergebnissen f√ºhren?</p>
</div>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">L√∂sung</p>
<p>Die unterschiedlichen Ergebnisse sind eine Folge davon, dass der Algorithmus mit zuf√§lligen Startpunkten arbeitet. Je nachdem, wo die Zentroiden am Anfang liegen, teilt der Algorithmus die Punkte unterschiedlich ein. Das zeigt, dass k-Means manchmal unterschiedliche Ergebnisse liefern kann, auch wenn die Daten gleich bleiben.</p>
<ul class="simple">
<li><p>Wenn ein Start-Zentroid mitten in einer dichten Datenmenge liegt, zieht er schnell viele Punkte an.</p></li>
<li><p>Liegt ein anderer Start-Zentroid weit weg, wird er vielleicht nur wenige Punkte anziehen.
Der Algorithmus findet also nicht immer die ‚Äòbeste‚Äô L√∂sung, sondern eine, die von den Startbedingungen abh√§ngt</p></li>
</ul>
</div>
<section id="initialisierung-der-clusterzentren-mit-kmeans">
<h3><span class="section-number">22.5.1. </span>Initialisierung der Clusterzentren mit k‚Äëmeans++<a class="headerlink" href="#initialisierung-der-clusterzentren-mit-kmeans" title="Link to this heading">#</a></h3>
<p><strong>[k-means++(<a class="reference external" href="https://de.wikipedia.org/wiki/K-Means-Algorithmus">https://de.wikipedia.org/wiki/K-Means-Algorithmus</a>)]</strong> ist eine verbesserte Methode zur Initialisierung der Clusterzentren beim k-means-Clustering. Es verbessert die Qualit√§t und Effizienz des Algorithmus durch folgende Schritte:</p>
<ol class="arabic simple">
<li><p><strong>Erster Startpunkt</strong>:</p>
<ul class="simple">
<li><p>Ein Punkt wird zuf√§llig aus den Daten gew√§hlt.</p></li>
</ul>
</li>
<li><p><strong>Gewichtete Auswahl der weitere Startpunkte</strong>:</p>
<ul class="simple">
<li><p>F√ºr jeden weiteren Startpunkt wird ein Punkt basierend auf seiner Distanz zu den n√§chsten bereits gew√§hlten Startpunkten ausgew√§hlt:</p>
<ul>
<li><p>Punkte, die weiter entfernt sind, haben eine h√∂here Wahrscheinlichkeit, ausgew√§hlt zu werden.</p></li>
<li><p>Die Wahrscheinlichkeit ist proportional zum Quadrat der Distanz zum n√§chsten Startpunkt (<span class="math notranslate nohighlight">\(D^2\)</span>).</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Wiederhole Schritt 2</strong>, bis <span class="math notranslate nohighlight">\(k\)</span> Startpunkte bestimmt sind.</p></li>
<li><p><strong>F√ºhre anschlie√üend das normale k-means-Verfahren durch</strong>.</p></li>
</ol>
<p><strong>Vorteil:</strong> Die Startpunkte werden optimal verteilt, was zu schnellerer Konvergenz und besseren Clustering-Ergebnissen f√ºhrt.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Wie funktioniert die gewichtete Auswahl genau?</strong></p>
<p>Angenommen, es gibt 5 Punkte mit diesen Distanzen zu den bestehenden Zentren:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Punkt</p></th>
<th class="head"><p>Entfernung <span class="math notranslate nohighlight">\(D\)</span></p></th>
<th class="head"><p>Gewicht <span class="math notranslate nohighlight">\(D^2\)</span></p></th>
<th class="head"><p>Wahrscheinlichkeit</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(A\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1^2 = 1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1 / (1 + 9 + 25 + 36 + 64) = 1/135 \approx 0.74\%\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(B\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3^2 = 9\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(9 / 135 \approx 6.67\%\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(C\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(5\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(5^2 = 25\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(25 / 135 \approx 18.52\%\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(D\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(6\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(6^2 = 36\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(36 / 135 \approx 26.67\%\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(E\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(8\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(8^2 = 64\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(64 / 135 \approx 47.41\%\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div style="margin-top: 20px;"></div>
<p>Punkt <span class="math notranslate nohighlight">\(E\)</span> hat die gr√∂√üte Wahrscheinlichkeit, gew√§hlt zu werden, aber nicht zu 100%. Es kann jedoch auch jeder andere Punkt gew√§hlt werden, abh√§ngig von seiner Wahrscheinlichkeit.</p>
</div>
</section>
</section>
<section id="ein-beispiel-zum-nachrechnen">
<h2><span class="section-number">22.6. </span>Ein Beispiel zum Nachrechnen<a class="headerlink" href="#ein-beispiel-zum-nachrechnen" title="Link to this heading">#</a></h2>
<p>Du wei√üt nun, wie der Algorithmus funktioniert und zu welchen Ergebnissen er f√ºhren kann. Am besten kannst du das nachvollziehen, indem du den Algorithmus selbst mal durchf√ºhrst. Lade dir dieses
<a class="reference download internal" download="" href="../_downloads/2d91cf82f12585d06b6443a793bb352d/kmeansclustering_aufgabenblatt.pdf"><code class="xref download docutils literal notranslate"><span class="pre">Aufgabenblatt</span></code></a> herunter und bearbeite es. Die Anweisungen findest du dem Arbeitsblatt. Viel Erfolg üí™</p>
</section>
<section id="die-richtige-wahl-fur-k-mit-der-elbow-methode">
<h2><span class="section-number">22.7. </span>Die richtige Wahl f√ºr <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode<a class="headerlink" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode" title="Link to this heading">#</a></h2>
<p>Bisher haben wir f√ºr unsere Beispiele <span class="math notranslate nohighlight">\(k\)</span> so gew√§hlt, dass es dem Verst√§ndnis passte. Doch in der Praxis stellt sich oft die Frage: <strong>Wie w√§hle ich die optimale Anzahl von <span class="math notranslate nohighlight">\(k\)</span> Clustern ?</strong></p>
<p>Hier kommt die <strong>Elbow-Methode</strong> ins Spiel. Sie hilft uns, auf systematische Weise die Anzahl der Cluster zu bestimmen, die sowohl eine gute Datenaufteilung gew√§hrleistet als auch unn√∂tig viele Cluster vermeidet.</p>
<p>Die Idee der Methode ist wie folgt:</p>
<ul class="simple">
<li><p>Wir berechnen die sogenannte <strong>Tr√§gheit</strong> (Summe der Abst√§nde der Datenpunkte zu ihren Clusterzentren) f√ºr verschiedene Werte von <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
<li><p>Die Tr√§gheit nimmt mit steigender Clusteranzahl <span class="math notranslate nohighlight">\(k\)</span> ab, weil mehr Cluster zu kleineren Distanzen f√ºhren.</p></li>
<li><p>Jedoch flacht die Abnahme ab, und ab einem bestimmten Punkt lohnt es sich nicht mehr, die Anzahl der Cluster weiter zu erh√∂hen. Dieser Punkt wird als <strong>Knickpunkt (Elbow)</strong> bezeichnet.</p></li>
</ul>
<figure class="align-center" id="fig-kmeans-elbow-demo-svg">
<a class="reference internal image-reference" href="../_images/kmeans_elbow_demo.svg"><img alt="../_images/kmeans_elbow_demo.svg" src="../_images/kmeans_elbow_demo.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.8 </span><span class="caption-text">Demonstration der Elbow-Methode</span><a class="headerlink" href="#fig-kmeans-elbow-demo-svg" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Die optimale Anzahl der Cluster <span class="math notranslate nohighlight">\(k\)</span> ist genau dort, wo dieser Knickpunkt liegt. Dies ist der Punkt, an dem die Verbesserung durch mehr Cluster stark nachl√§sst, und wir eine gute Balance zwischen Genauigkeit und Einfachheit erreichen.</p>
<div class="note admonition">
<p class="admonition-title">Warum funktioniert die Elbow-Methode?</p>
<p>Die Methode basiert auf der Idee, dass eine kleine Anzahl von Clustern zu einer schlechten Gruppierung f√ºhrt, w√§hrend eine zu gro√üe Anzahl von Clustern unn√∂tig ist und zu <a class="reference internal" href="#overfitting"><span class="xref myst">Overfitting</span></a> f√ºhren kann. Der Knick bei Anzahl der Cluster <span class="math notranslate nohighlight">\(= 2\)</span> zeigt den Punkt, an dem sich der Aufwand f√ºr mehr Cluster nicht mehr lohnt.</p>
</div>
<p>Mit der Elbow-Methode k√∂nnen wir also datengetrieben und anschaulich entscheiden, wie viele Cluster sinnvoll sind, anstatt dies nur durch Intuition oder Versuch und Irrtum zu bestimmen.</p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

        <script type="text/x-thebe-config">
        {
            "rootPath": "..",
            "requestKernel": true,
            "useJupyterLite": true,
            "useBinder": false,
            "kernelOptions": {
                "path": "/"
            },
            "codeMirrorConfig": {
                "theme": "default",
                "mode": "python"
            },
            "mountRestartButton": false,
            "mountRestartallButton": false
        }
        </script>
        <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="knearestneighbor2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">zur√ºck</p>
        <p class="prev-next-title"><span class="section-number">21.6. </span>Eigenschaften und Varianten des k-N√§chste-Nachbarn-Algorithmus</p>
      </div>
    </a>
    <a class="right-next"
       href="kmeansclustering2_aufgabe.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title"><span class="section-number">22.8. </span>Programmierung des Algorithmus</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Inhalt
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uberwachtes-vs-unuberwachtes-lernen">22.1. √úberwachtes vs. un√ºberwachtes Lernen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einfuhrung-in-das-verfahren">22.2. Einf√ºhrung in das Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#der-k-means-clustering-algorithmus">22.3. Der k-means-Clustering Algorithmus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reale-anwendungsbeispiele">22.4. Reale Anwendungsbeispiele</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-konkretes-beispiel-clustering-von-obstsorten">22.5. Ein konkretes Beispiel: Clustering von Obstsorten</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisierung-der-clusterzentren-mit-kmeans">22.5.1. Initialisierung der Clusterzentren mit k‚Äëmeans++</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-beispiel-zum-nachrechnen">22.6. Ein Beispiel zum Nachrechnen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode">22.7. Die richtige Wahl f√ºr <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Durch Michael Brenner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
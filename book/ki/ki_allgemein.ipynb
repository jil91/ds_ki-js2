{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Künstliche Intelligenz: Einführung\n",
    "\n",
    "Die Künstliche Intelligenz ist ein weites Feld, das man aus verschiedenen Perspektiven betrachten kann.\n",
    "\n",
    "Fürs Abitur am TG Informationstechnik sind im Augenblick nur die folgenden Themen relevant - und in diesem Skript werden deshalb auch nur sie ausführlich behandelt. In unserem *Moodle-Kurs* findest du weitere Materialien, insb. zu den gesellschaflichen Auswirkungen von KI und dazu, wie du selbst KI nutzen kannst, sollst, darfst (und an manchen Stellen auch besser *nicht* nutzen sollst oder darfst) .\n",
    "\n",
    "## KI-Themen, die fürs Abitur in Informationstechnik relevant sind\n",
    "\n",
    "* Der k-Nächste-Nachbarn-Algorithmus\n",
    "* k-Means-Clustering\n",
    "* Entscheidungsbaumlernen\n",
    "* Der Minimax-Algorithmus für Zwei-Personen-Spiele\n",
    "* Neuronale Netze\n",
    "\n",
    "(sec:glossar_ki)=\n",
    "## Wichtige Begriffe\n",
    "\n",
    "Die KI ist voller Fachbegriffe. Hier kannst du nachschlagen, wenn du auf einen Begriff stößt, den du nicht kennst.\n",
    "\n",
    "{.glossary}\n",
    "\n",
    "Aktivierungsfunktion (nicht klausurrelevant)\n",
    ": Eine mathematische Funktion, die die Ausgabe eines künstlichen {term}`Neurons <Neuron>` transformiert. Sie entscheidet, ob ein Neuron \"aktiviert\" wird. Beispiele: Sigmoid, ReLU, Heaviside. (s. {term}`Neuronales Netz <Neuronales Netz>`, {term}`Perzeptron <Perzeptron>`)\n",
    "\n",
    "Backpropagation (nicht klausurrelevant)\n",
    ": Eine Methode, die es einem {term}`Neuronalen Netz <Neuronales Netz>` ermöglicht, Fehler zu korrigieren, indem es sie rückwärts durch die Schichten sendet. Das Modell passt so seine Gewichte an, um bessere Vorhersagen zu treffen. (s. {term}`Gradientenabstieg <Gradientenabstieg>`, {term}`Trainingsdaten <Trainingsdaten>`)\n",
    "\n",
    "Bestärkendes Lernen (nicht klausurrelevant)\n",
    ": siehe {term}`Verstärkendes Lernen`.\n",
    "\n",
    "Datenpunkt  \n",
    ": Eine einzelne Beobachtung in einem Datensatz, bestehend aus {term}`Features <Merkmal>` und ggf. einem {term}`Label <Label>`. Beispiel: Ein Datenpunkt könnte das Alter und Gewicht einer Person enthalten.\n",
    "\n",
    "Distanzmaße  \n",
    ": Metriken zur Messung der Ähnlichkeit oder Unterschiedlichkeit zwischen {term}`Datenpunkten <Datenpunkt>`. Beispiele: {term}`Euklidische Distanz <Euklidische Distanz>`, {term}`Manhattan-Distanz <Manhattan-Distanz>`.\n",
    "\n",
    "Eifriger Lerner  \n",
    ": Ein Ansatz, bei dem das Modell vollständig trainiert wird, bevor es Vorhersagen trifft. Beispiele: {term}`Entscheidungsbaumlernen <Entscheidungsbaumlernen>`, {term}`Neuronales Netz <Neuronales Netz>`. (s. {term}`Fauler Lerner <Fauler Lerner>`)\n",
    "\n",
    "Entscheidungsbaum  \n",
    ": Eine hierarchische Struktur, die Entscheidungen durch Regeln modelliert, z. B. \"Ist das Alter > 18?\". Jeder Knoten repräsentiert eine Regel, die die Daten aufteilt. (s. {term}`Entscheidungsbaumlernen <Entscheidungsbaumlernen>`, {term}`Gini-Unreinheit <Gini-Unreinheit>`)\n",
    "\n",
    "Entscheidungsbaumlernen  \n",
    ": Ein Algorithmus, der einen {term}`Entscheidungsbaum <Entscheidungsbaum>` erstellt, indem er die Daten basierend auf Kriterien wie der {term}`Gini-Unreinheit <Gini-Unreinheit>` aufteilt.\n",
    "\n",
    "Epoche (nicht klausurrelevant)\n",
    ": Eine vollständige Iteration durch den gesamten {term}`Trainingsdatensatz <Trainingsdaten>` während des Trainings eines Modells.\n",
    "\n",
    "Euklidische Distanz\n",
    ": Eine {term}`Distanzmetrik <Distanzmaße>`, welche die direkte Strecke (Luftlinie) zwischen zwei Punkten misst. Sie wird berechnet, indem man die Differenzen der Koordinaten quadriert, addiert und daraus die Wurzel zieht. Beispiel: Die Euklidische Distanz zwischen den Punkten (1, 2) und (4, 6) beträgt $\\sqrt{(1-4)^2 + (2-6)^2} = \\sqrt{9 + 16} = 5$.\n",
    "\n",
    "Fauler Lerner  \n",
    ": Ein Ansatz, bei dem das Modell erst zur Laufzeit (also bei einer Anfrage) trainiert wird, anstatt vorher. Beispiele: {term}`K-Nächste-Nachbarn-Algorithmus <K-Nächste-Nachbarn-Algorithmus>`. (s. {term}`Eifriger Lerner <Eifriger Lerner>`)\n",
    "\n",
    "Feature  \n",
    ": (s. {term}`Merkmal <Merkmal>`)\n",
    "\n",
    "Gelabelte vs ungelabelte Daten\n",
    ": **Gelabelte Daten** enthalten sowohl Eingabewerte ({term}`Features <Merkmal>`) als auch die zugehörigen Zielwerte ({term}`Labels <Label>`). Sie werden für **überwachtes Lernen** verwendet. Beispiel: Bilder von Tieren mit der Angabe \"Hund\" oder \"Katze\".  \n",
    "**Ungelabelte Daten** enthalten nur Eingabewerte ohne Zielwerte. Sie werden für **unüberwachtes Lernen** verwendet, um Muster oder Strukturen zu erkennen. Beispiel: Kundenkaufdaten ohne vordefinierte Kategorien. (s. {term}`Überwachtes Lernen <Überwachtes Lernen>`, {term}`Unüberwachtes Lernen <Unüberwachtes Lernen>`)\n",
    "\n",
    "Gini-Unreinheit  \n",
    ": Ein Maß für die Reinheit eines Knotens in einem {term}`Entscheidungsbaum <Entscheidungsbaum>`. Ein Wert von 0 bedeutet, dass alle Daten zur gleichen Kategorie gehören.\n",
    "\n",
    "Gradientenabstieg (nicht klausurrelevant)\n",
    ": Ein Algorithmus, der Schritt für Schritt die Fehler eines Modells reduziert, indem er die Parameter so anpasst, dass die Fehlerfunktion kleiner wird. (s. {term}`Backpropagation <Backpropagation>`, {term}`Lernrate <Lernrate>`)\n",
    "\n",
    "k-Means Clustering  \n",
    ": Ein Algorithmus, der {term}`Datenpunkte <Datenpunkt>` in $k$ Gruppen (Cluster) aufteilt, indem er iterativ ihre Ähnlichkeit optimiert.\n",
    "\n",
    "k-Nächste-Nachbarn-Algorithmus  \n",
    ": Ein Algorithmus, der Vorhersagen basierend auf den $k$ ähnlichsten {term}`Datenpunkten <Datenpunkt>` trifft. Beispiel: Die 3 nächsten Nachbarn eines Punktes bestimmen, ob er eher \"Katze\" oder \"Hund\" ist. (s. {term}`Distanzmaße <Distanzmaße>`)\n",
    "\n",
    "Klassifikation  \n",
    ": Eine Form des {term}`überwachten Lernens <Überwachtes Lernen>`, bei der ein Modell Eingabedaten einer oder mehreren Kategorien zuordnet. Beispiel: Ein Modell klassifiziert E-Mails als \"Spam\" oder \"Nicht-Spam\". (s. {term}`Regression <Regression>`)\n",
    "\n",
    "Label  \n",
    ": Die bekannte Zielgröße oder Kategorie eines {term}`Datenpunkts <Datenpunkt>`, z. B. \"Spam\" oder \"Nicht-Spam\". (s. {term}`Gelabelte vs ungelabelte Daten <Gelabelte vs ungelabelte Daten>`)\n",
    "\n",
    "Lerner vs Löser  \n",
    ": **Lerner** sind Algorithmen, die ein Modell aus Daten erstellen, z. B. {term}`Neuronale Netze <Neuronales Netz>` oder {term}`Entscheidungsbaumlernen <Entscheidungsbaumlernen>`. **Löser** arbeiten direkt auf einer Problemstruktur, z. B. der {term}`Minimax-Algorithmus <Minimax-Algorithmus>`.\n",
    "\n",
    "Lernrate (nicht klausurrelevant)  \n",
    ": Ein Hyperparameter, der bestimmt, wie groß die Schritte beim {term}`Gradientenabstieg <Gradientenabstieg>` sind. Eine zu hohe Lernrate kann das Lernen instabil machen, eine zu niedrige führt zu langsamen Fortschritten.\n",
    "\n",
    "Manhattan-Distanz  \n",
    ": Eine {term}`Distanzmetrik <Distanzmaße>`, die die Summe der absoluten Differenzen zwischen den Koordinaten zweier Punkte berechnet. Beispiel: Die Manhattan-Distanz zwischen den Punkten (1, 2) und (4, 6) beträgt $|1-4| + |2-6| = 7$.\n",
    "\n",
    "Merkmal\n",
    ": Merkmale (engl. *features*) beschreiben die Eigenschaften eines {term}`Datenpunkts <Datenpunkt>`. Beispiel: In einem Datensatz über Personen könnten Merkmale wie *Alter* oder *Körpergröße* enthalten sein.\n",
    "\n",
    "Minimax-Algorithmus  \n",
    ": Ein Entscheidungsalgorithmus, der in Spielen wie Schach verwendet wird, um optimale Züge zu finden. Beispiel: Der Algorithmus berechnet den besten Zug, indem er den schlechtesten Zug des Gegners minimiert. (s. {term}`Entscheidungsbaum <Entscheidungsbaum>`)\n",
    "\n",
    "Neuron (nicht klausurrelevant) \n",
    ": Die grundlegende Recheneinheit in einem {term}`Neuronalen Netz <Neuronales Netz>`. Es nimmt Eingaben entgegen, verarbeitet sie mit einer {term}`Aktivierungsfunktion <Aktivierungsfunktion>` und gibt eine Ausgabe weiter. (s. {term}`Perzeptron <Perzeptron>`)\n",
    "\n",
    "Neuronales Netz (nicht klausurrelevant)  \n",
    ": Ein Modell, das aus mehreren Schichten künstlicher {term}`Neuronen <Neuron>` besteht. Es lernt komplexe Muster, indem es die Verbindungen zwischen den Neuronen anpasst. (s. {term}`Backpropagation <Backpropagation>`)\n",
    "\n",
    "Overfitting  \n",
    ": Die Situation, wenn ein Modell die {term}`Trainingsdaten <Trainingsdaten>` zu genau lernt und dadurch schlecht auf neue Daten generalisiert. Beispiel: Ein Modell, das jeden Datenpunkt \"auswendig\" gelernt hat. (s. {term}`Underfitting <Underfitting>`, {term}`Regularisierung <Regularisierung>`)\n",
    "\n",
    "Perzeptron (nicht klausurrelevant)  \n",
    ": Das einfachste Modell eines künstlichen {term}`Neurons <Neuron>`. Es trifft Entscheidungen basierend auf einer linearen Entscheidungsregel. Beispiel: Ein Perzeptron entscheidet, ob ein Punkt links oder rechts einer Linie liegt. (s. {term}`Neuronales Netz <Neuronales Netz>`)\n",
    "\n",
    "Regularisierung (nicht klausurrelevant)  \n",
    ": Eine Methode, um zu verhindern, dass ein Modell **Overfitting** betreibt. \n",
    "Bei der Regularisierung wird das Modell dafür bestraft, wenn seine Parameter zu groß oder zu komplex werden. Dadurch wird das Modell \"einfacher\" gehalten. (s. {term}`Overfitting <Overfitting>`, {term}`Underfitting <Underfitting>`)\n",
    "\n",
    "Regression (nicht klausurrelevant)  \n",
    ": Eine Form des {term}`überwachten Lernens <Überwachtes Lernens>`, bei der ein Modell kontinuierliche Werte vorhersagt, z. B. den Preis eines Hauses. (s. {term}`Klassifikation <Klassifikation>`)\n",
    "\n",
    "Softmax-Funktion (nicht klausurrelevant)  \n",
    ": Eine Methode, um die Ausgaben mehrerer Neuronen in Wahrscheinlichkeiten umzuwandeln, sodass ihre Summe genau 1 ergibt. Große Ausgabewerte werden stärker gewichtet, kleinere weniger. Beispiel: Ein Modell gibt aus, dass es zu 80 % \"Katze\" und zu 20 % \"Hund\" ist. (s. {term}`Klassifikation <Klassifikation>`)\n",
    "\n",
    "Testdaten  \n",
    ": Daten, die verwendet werden, um die Leistung eines Modells zu überprüfen. Beispiel: Neue Daten, die das Modell vorher nicht gesehen hat. (s. {term}`Trainingsdaten <Trainingsdaten>`)\n",
    "\n",
    "Trainingsdaten  \n",
    ": Daten, die verwendet werden, um ein Modell zu trainieren. Beispiel: Ein Datensatz mit Bildern von Katzen und Hunden, den das Modell verwendet, um sie zu unterscheiden. (s. {term}`Testdaten <Testdaten>`)\n",
    "\n",
    "Überwachtes Lernen  \n",
    ": Eine Lernmethode, bei der das Modell mit gelabelten Daten trainiert wird. Beispiel: Ein Modell lernt, Spam von Nicht-Spam zu unterscheiden. (s. {term}`Gelabelte vs ungelabelte Daten <Gelabelte vs ungelabelte Daten>`)\n",
    "\n",
    "Unüberwachtes Lernen  \n",
    ": Eine Methode, bei der ein Modell mit ungelabelten Daten trainiert wird, um Muster oder Strukturen zu erkennen. Beispiel: Gruppieren von Kunden nach ihren Kaufgewohnheiten. (s. {term}`Gelabelte vs ungelabelte Daten <Gelabelte vs ungelabelte Daten>`)\n",
    "\n",
    "Underfitting  \n",
    ": Die Situation, wenn ein Modell zu einfach ist und die zugrunde liegenden Muster in den {term}`Trainingsdaten <Trainingsdaten>` nicht erfasst. Beispiel: Ein Modell, das eine komplexe Beziehung als gerade Linie darstellt. (s. {term}`Overfitting <Overfitting>`)\n",
    "\n",
    "Verstärkendes Lernen (nicht klausurrelevant)  \n",
    ": Eine Methode, bei der ein Agent durch Belohnungen und Bestrafungen lernt, sein Verhalten zu optimieren. Beispiel: Ein Roboter lernt, einen Hindernisparcours zu meistern. (s. {term}`Bestärkendes Lernen <Bestärkendes Lernen>`)\n",
    "\n",
    "Zielmerkmal\n",
    ": Dasjenige Merkmal, das *vorhergesagt* werden soll. Beispiel: In einer Bilderdatenbank könnte das Zielmerkmal die Kategorie des Bildes sein, z. B. \"Katze\" oder \"Hund\". (s. {term}`Merkmal <Merkmal>`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

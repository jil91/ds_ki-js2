selector_to_html = {"a[href=\"#k-means-clustering\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23. </span>k-Means-Clustering<a class=\"headerlink\" href=\"#k-means-clustering\" title=\"Link to this heading\">#</a></h1><p>Du kennst bereits den <a class=\"reference internal\" href=\"knearestneighbor.html\"><span class=\"doc std std-doc\">k-N\u00e4chste-Nachbarn-Algorithmus</span></a>, ein Verfahren, das mit <a class=\"reference internal\" href=\"ki_allgemein.html#term-Trainingsdaten\"><span class=\"xref std std-term\">Trainingsdaten</span></a> neue Daten klassifiziert. Nun betrachten wir <a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/k-Means-Algorithmus\">k-Means-Clustering</a>, einen Algorithmus, um <a class=\"reference internal\" href=\"ki_allgemein.html#term-Datenpunkt\"><span class=\"xref std std-term\">Datenpunkte</span></a> in sogenannte Cluster zu gruppieren.</p><p>Im Bereich der KI wird oft mit gro\u00dfen Datenmengen gearbeitet, die auf Muster untersucht und in Gruppen eingeteilt werden. Algorithmen dieser Art sind Verfahren der <a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/Clusteranalyse\">Clusteranalyse</a>. k-Means ist so ein Algorithmus, der Datenpunkte ohne vorherige Kenntnis der Gruppenzugeh\u00f6rigkeit in <span class=\"math notranslate nohighlight\">\\(k\\)</span> Cluster einteilt. Das macht k-Means zu einem <a class=\"reference internal\" href=\"ki_allgemein.html#term-Unuberwachtes-Lernen\"><span class=\"xref std std-term\">un\u00fcberwachten Lernalgorithmus</span></a>. Seine St\u00e4rke liegt in der effizienten Strukturierung gro\u00dfer Datens\u00e4tze und dem Entdecken versteckter Muster.</p>", "a[href=\"ki_allgemein.html#term-Trainingsdaten\"]": "<dt id=\"term-Trainingsdaten\">Trainingsdaten</dt><dd><p>Daten, die verwendet werden, um ein Modell zu trainieren. Beispiel: Ein Datensatz mit Bildern von Katzen und Hunden, den das Modell verwendet, um sie zu unterscheiden. (s. <a class=\"reference internal\" href=\"#term-Testdaten\"><span class=\"xref std std-term\">Testdaten</span></a>)</p></dd>", "a[href=\"#ein-beispiel-zum-nachrechnen\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.6. </span>Ein Beispiel zum Nachrechnen<a class=\"headerlink\" href=\"#ein-beispiel-zum-nachrechnen\" title=\"Link to this heading\">#</a></h2><p>Du wei\u00dft nun, wie der Algorithmus funktioniert und zu welchen Ergebnissen er f\u00fchren kann. Am besten kannst du das nachvollziehen, indem du den Algorithmus selbst mal durchf\u00fchrst. Lade dir dieses\n<a class=\"reference download internal\" download=\"\" href=\"../_downloads/2d91cf82f12585d06b6443a793bb352d/kmeansclustering_aufgabenblatt.pdf\"><code class=\"xref download docutils literal notranslate\"><span class=\"pre\">Aufgabenblatt</span></code></a> herunter und bearbeite es. Die Anweisungen findest du dem Arbeitsblatt. Viel Erfolg \ud83d\udcaa</p>", "a[href=\"ki_allgemein.html#term-Unuberwachtes-Lernen\"]": "<dt id=\"term-Unuberwachtes-Lernen\">Un\u00fcberwachtes Lernen</dt><dd><p>Eine Methode, bei der ein Modell mit ungelabelten Daten trainiert wird, um Muster oder Strukturen zu erkennen. Beispiel: Gruppieren von Kunden nach ihren Kaufgewohnheiten. (s. <a class=\"reference internal\" href=\"#term-Gelabelte-vs-ungelabelte-Daten\"><span class=\"xref std std-term\">Gelabelte vs ungelabelte Daten</span></a>)</p></dd>", "a[href=\"#uberwachtes-vs-unuberwachtes-lernen\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.1. </span>\u00dcberwachtes vs. un\u00fcberwachtes Lernen<a class=\"headerlink\" href=\"#uberwachtes-vs-unuberwachtes-lernen\" title=\"Link to this heading\">#</a></h2><p>Beide Algorithmen stammen aus dem Bereich <strong>Maschinelles Lernen</strong>, welches grob in <strong>\u00fcberwachtes Lernen</strong> und <strong>un\u00fcberwachtes Lernen</strong> unterteilt wird. Beim <a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen\">\u00fcberwachten Lernen</a> wird ein Datensatz verwendet, der Trainingsdaten mit den zugeh\u00f6rigen <strong><a class=\"reference internal\" href=\"ki_allgemein.html#term-Label\"><span class=\"xref std std-term\">Labels</span></a></strong> enth\u00e4lt. Das Modell lernt aus Beispielen, bei denen die richtigen Antworten bereits bekannt sind. Diese Methode eignet sich gut f\u00fcr Aufgaben wie Klassifikationen (z.B. Spam-Erkennung). Der <a class=\"reference internal\" href=\"knearestneighbor.html\"><span class=\"doc std std-doc\">k-N\u00e4chste-Nachbarn-Algorithmus</span></a> ist ein solches Verfahren.</p><p>Beim <a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/Un%C3%BCberwachtes_Lernen\">un\u00fcberwachten Lernen</a> sind die Trainingsdaten nicht gelabelt. Stattdessen versuchen un\u00fcberwachte Algorithmen, eigenst\u00e4ndig Muster in den Daten zu erkennen. Clustering, wie k-Means, ist ein typisches Beispiel daf\u00fcr. Der Algorithmus ermittelt Gruppen (Cluster) von \u00e4hnlichen Datenpunkten und hilft, ungeordnete Daten zu strukturieren.</p>", "a[href=\"knearestneighbor.html\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">22. </span>Der k-N\u00e4chste-Nachbarn-Algorithmus<a class=\"headerlink\" href=\"#der-k-nachste-nachbarn-algorithmus\" title=\"Link to this heading\">#</a></h1><p>Der <a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/N%C3%A4chste-Nachbarn-Klassifikation\">k-N\u00e4chste-Nachbarn-Algorithmus</a> klassifiziert\neinen bisher ungelabelten Datensatz, indem er ihn mit seinen \u201cn\u00e4chsten Nachbarn\u201d vergleicht, d.h. mit\ndenjenigen bereits gelabelten Datens\u00e4tzen, die dem neuen Datensatz <em>am \u00e4hnlichsten</em> sind.<br/>\nDem unbekannten Datensatz wird dann dasjenige Label zugeordnet, das die <em>Mehrheit</em> der \u201cNachbarn\u201d hat.</p><p>Klingt kompliziert? Keine Sorge - das Verfahren ist total einfach.  Am folgenden <em>interaktiven</em> Beispiel wirst du schnell verstehen, wie der k-N\u00e4chste-Nachbarn-Algorithmus funktioniert.</p>", "a[href=\"#der-k-means-clustering-algorithmus\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.3. </span>Der k-means-Clustering Algorithmus<a class=\"headerlink\" href=\"#der-k-means-clustering-algorithmus\" title=\"Link to this heading\">#</a></h2><p>Der Ablauf des k-means-Clustering Algorithmus wird in folgende Schritte aufgeteilt:</p>", "a[href=\"#fig-kmeans-3-cluster-komplex-ergebnis\"]": "<figure class=\"align-center\" id=\"fig-kmeans-3-cluster-komplex-ergebnis\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_4_cluster_komplex_ergebnis.svg\"><img alt=\"../_images/kmeans_4_cluster_komplex_ergebnis.svg\" src=\"../_images/kmeans_4_cluster_komplex_ergebnis.svg\" style=\"width: 90%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.4 </span><span class=\"caption-text\">Ergebnis des k-Means-Clustering mit k=4</span><a class=\"headerlink\" href=\"#fig-kmeans-3-cluster-komplex-ergebnis\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#reale-anwendungsbeispiele\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.4. </span>Reale Anwendungsbeispiele<a class=\"headerlink\" href=\"#reale-anwendungsbeispiele\" title=\"Link to this heading\">#</a></h2><p>Welche realen Anwendungsbeispiele kannst du dir vorstellen, bei denen das k-means Clustering eingesetzt werden k\u00f6nnte?</p><p>\u00dcberlege dabei, in welchen Bereichen es wichtig sein k\u00f6nnte, Daten in Gruppen aufzuteilen, ohne dass bereits vorgegeben ist, zu welcher Gruppe ein Datenpunkt geh\u00f6rt. Welche Situationen kennst du, in denen Menschen, Dinge oder Objekte aufgrund ihrer \u00c4hnlichkeit in Gruppen eingeteilt werden? Es gibt hier keine richtige Antwort, nur eine Auswahl an m\u00f6glichen Einsatzszenarien.</p>", "a[href=\"ki_allgemein.html#term-Datenpunkt\"]": "<dt id=\"term-Datenpunkt\">Datenpunkt</dt><dd><p>Eine einzelne Beobachtung in einem Datensatz, bestehend aus <a class=\"reference internal\" href=\"#term-Merkmal\"><span class=\"xref std std-term\">Features</span></a> und ggf. einem <a class=\"reference internal\" href=\"#term-Label\"><span class=\"xref std std-term\">Label</span></a>. Beispiel: Ein Datenpunkt k\u00f6nnte das Alter und Gewicht einer Person enthalten.</p></dd>", "a[href=\"ki_allgemein.html#term-Distanzmasze\"]": "<dt id=\"term-Distanzmasze\">Distanzma\u00dfe</dt><dd><p>Metriken zur Messung der \u00c4hnlichkeit oder Unterschiedlichkeit zwischen <a class=\"reference internal\" href=\"#term-Datenpunkt\"><span class=\"xref std std-term\">Datenpunkten</span></a>. Beispiele: <a class=\"reference internal\" href=\"#term-Euklidische-Distanz\"><span class=\"xref std std-term\">Euklidische Distanz</span></a>, <a class=\"reference internal\" href=\"#term-Manhattan-Distanz\"><span class=\"xref std std-term\">Manhattan-Distanz</span></a>.</p></dd>", "a[href=\"#fig-kmeans-obst-3\"]": "<figure class=\"align-center\" id=\"fig-kmeans-obst-3\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_obst_clusters_3.svg\"><img alt=\"../_images/kmeans_obst_clusters_3.svg\" src=\"../_images/kmeans_obst_clusters_3.svg\" style=\"width: 90%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.6 </span><span class=\"caption-text\">k-Means-Clustering der Obstsorten mit k=3</span><a class=\"headerlink\" href=\"#fig-kmeans-obst-3\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"ki_allgemein.html#term-Label\"]": "<dt id=\"term-Label\">Label</dt><dd><p>Die bekannte Zielgr\u00f6\u00dfe oder Kategorie eines <a class=\"reference internal\" href=\"#term-Datenpunkt\"><span class=\"xref std std-term\">Datenpunkts</span></a>, z. B. \u201cSpam\u201d oder \u201cNicht-Spam\u201d. (s. <a class=\"reference internal\" href=\"#term-Gelabelte-vs-ungelabelte-Daten\"><span class=\"xref std std-term\">Gelabelte vs ungelabelte Daten</span></a>)</p></dd>", "a[href=\"#ein-konkretes-beispiel-clustering-von-obstsorten\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.5. </span>Ein konkretes Beispiel: Clustering von Obstsorten<a class=\"headerlink\" href=\"#ein-konkretes-beispiel-clustering-von-obstsorten\" title=\"Link to this heading\">#</a></h2><p>Wir m\u00f6chten uns ges\u00fcnder ern\u00e4hren und wollen mehr Obst essen. Die WHO empfiehlt Obst mit hohen Fruchtzuckergehalt in geringen Ma\u00dfen zu genie\u00dfen. Obst mit einem hohen Wassergehalt f\u00fchrt zu einer h\u00f6heren S\u00e4ttigung. Nehmen wir an, wir haben Daten \u00fcber Obstsorten mit Informationen wie u.a. Wassergehalt und Fruchtzuckergehalt. Wir m\u00f6chten \u00e4hnliche Obstsorten in Clustern gruppieren, sodass die Obstsorten m\u00f6glichst homogen sind. Anhand der Cluster k\u00f6nnen wir dann entscheiden, welches Obst wir in welchen Mengen essen k\u00f6nnen.</p><p>Wir spielen dieses Beispiel mal nach und schauen uns das Ergebnis an. Die zuge\u00f6rigen Daten zu unseren Obstsorten sind:</p>", "a[href=\"#ablauf-k-means-algorithmus\"]": "<div class=\"admonition important\" id=\"ablauf-k-means-algorithmus\">\n<p class=\"admonition-title\">Wichtig</p>\n<p><strong>Auswahl der Anzahl der Cluster (<span class=\"math notranslate nohighlight\">\\(k\\)</span>)</strong><br/>\nBevor der Algorithmus gestartet werden, muss die <strong>Anzahl der Cluster</strong> <span class=\"math notranslate nohighlight\">\\(k\\)</span> festgelegt werden. Diese Zahl bestimmt, in wie viele Gruppen die Datenpunkte aufgeteilt werden sollen.</p>\n<p><strong>1. Initialisierung der Zentroiden</strong><br/>\nAls n\u00e4chstes werden <span class=\"math notranslate nohighlight\">\\(k\\)</span> Datenpunkte aus den Daten oder <span class=\"math notranslate nohighlight\">\\(k\\)</span> zuf\u00e4llige Punkte ausgew\u00e4hlt, um die anf\u00e4nglichen <strong>Zentroiden</strong> (Cluster-Zentren) zu bestimmen.</p>\n<p><strong>2. Zuweisung der Datenpunkte und Bildung der Cluster</strong><br/>\nJeder Datenpunkt wird dem n\u00e4chstgelegenen Zentroiden zugewiesen. Dies wird durch die <a class=\"reference internal\" href=\"ki_allgemein.html#term-Distanzmasze\"><span class=\"xref std std-term\">Distanzma\u00dfe</span></a> zu allen Zentroiden bestimmt (z.B. mittels <a class=\"reference internal\" href=\"ki_allgemein.html#term-Euklidische-Distanz\"><span class=\"xref std std-term\">Euklidischer Distanz</span></a> oder <a class=\"reference internal\" href=\"ki_allgemein.html#term-Manhattan-Distanz\"><span class=\"xref std std-term\">Manhattan-Distanz</span></a>).</p>\n<p><strong>3. Aktualisierung der Zentroiden</strong><br/>\nDie Zentroiden werden neu berechnet, indem der Durchschnitt (<strong>Mean</strong>) aller Punkte innerhalb eines Clusters berechnet wird.</p>\n<p><strong>4. Wiederholung der Schritte 3 und 4</strong><br/>\nDie Schritte 2 und 3 werden solange wiederholt, bis sich die Zentroiden nicht mehr \u00e4ndern oder eine maximale Anzahl an Iterationen erreicht ist.</p>\n</div>", "a[href=\"ki_allgemein.html#term-Euklidische-Distanz\"]": "<dt id=\"term-Euklidische-Distanz\">Euklidische Distanz</dt><dd><p>Eine <a class=\"reference internal\" href=\"#term-Distanzmasze\"><span class=\"xref std std-term\">Distanzmetrik</span></a>, welche die direkte Strecke (Luftlinie) zwischen zwei Punkten misst. Sie wird berechnet, indem man die Differenzen der Koordinaten quadriert, addiert und daraus die Wurzel zieht. Beispiel: Die Euklidische Distanz zwischen den Punkten (1, 2) und (4, 6) betr\u00e4gt <span class=\"math notranslate nohighlight\">\\(\\sqrt{(1-4)^2 + (2-6)^2} = \\sqrt{9 + 16} = 5\\)</span>.</p></dd>", "a[href=\"#fig-kmeans-3-cluster-einfach-datenpunkte\"]": "<figure class=\"align-center\" id=\"fig-kmeans-3-cluster-einfach-datenpunkte\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_3_cluster_einfach_datenpunkte.svg\"><img alt=\"../_images/kmeans_3_cluster_einfach_datenpunkte.svg\" src=\"../_images/kmeans_3_cluster_einfach_datenpunkte.svg\" style=\"width: 80%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.1 </span><span class=\"caption-text\">Beispiel von einfacher Verteilung von Datenpunkten</span><a class=\"headerlink\" href=\"#fig-kmeans-3-cluster-einfach-datenpunkte\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#initialisierung-der-clusterzentren-mit-kmeans\"]": "<h3 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.5.1. </span>Initialisierung der Clusterzentren mit k\u2011means++<a class=\"headerlink\" href=\"#initialisierung-der-clusterzentren-mit-kmeans\" title=\"Link to this heading\">#</a></h3><p><strong>[k-means++(<a class=\"reference external\" href=\"https://de.wikipedia.org/wiki/K-Means-Algorithmus\">https://de.wikipedia.org/wiki/K-Means-Algorithmus</a>)]</strong> ist eine verbesserte Methode zur Initialisierung der Clusterzentren beim k-means-Clustering. Es verbessert die Qualit\u00e4t und Effizienz des Algorithmus durch folgende Schritte:</p>", "a[href=\"#fig-kmeans-3-cluster-komplex-datenpunkte\"]": "<figure class=\"align-center\" id=\"fig-kmeans-3-cluster-komplex-datenpunkte\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_4_cluster_komplex_datenpunkte.svg\"><img alt=\"../_images/kmeans_4_cluster_komplex_datenpunkte.svg\" src=\"../_images/kmeans_4_cluster_komplex_datenpunkte.svg\" style=\"width: 80%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.3 </span><span class=\"caption-text\">Beispiel von komplexer Verteilung von Datenpunkten</span><a class=\"headerlink\" href=\"#fig-kmeans-3-cluster-komplex-datenpunkte\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#fig-kmeans-obst-42\"]": "<figure class=\"align-center\" id=\"fig-kmeans-obst-42\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_obst_clusters_42.svg\"><img alt=\"../_images/kmeans_obst_clusters_42.svg\" src=\"../_images/kmeans_obst_clusters_42.svg\" style=\"width: 90%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.7 </span><span class=\"caption-text\">k-Means-Clustering der Obstsorten mit k=3 Variante 2</span><a class=\"headerlink\" href=\"#fig-kmeans-obst-42\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#einfuhrung-in-das-verfahren\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.2. </span>Einf\u00fchrung in das Verfahren<a class=\"headerlink\" href=\"#einfuhrung-in-das-verfahren\" title=\"Link to this heading\">#</a></h2><p>k-Means-Clustering geh\u00f6rt zum <strong>un\u00fcberwachten Lernen</strong>. Es gibt keine vordefinierten Labels, sondern nur die rohen Daten. Das Ziel von k-Means ist es, die Daten in <strong><span class=\"math notranslate nohighlight\">\\(k\\)</span> Cluster</strong> zu unterteilen, wobei <span class=\"math notranslate nohighlight\">\\(k\\)</span> die Anzahl der Cluster darstellt. Der Algorithmus ermittelt <strong>Zentroiden</strong>, auch Clusterzentren genannt. Das sind die Mittelpunkte, um die sich die Cluster bilden. <strong>Means</strong> steht dabei f\u00fcr den Durchschnitt, da die Zentroiden als Durchschnitt der zugeh\u00f6rigen Datenpunkte im Cluster berechnet werden. Am Ende sind die Daten innerhalb eines Clusters homogener als zu den Daten in anderen Clustern.</p><p>In einfachen Beispielen k\u00f6nnten wir die Cluster auch mit dem Auge erkennen und auch ablesen, welche Zahl f\u00fcr <span class=\"math notranslate nohighlight\">\\(k\\)</span> sinnvoll w\u00e4re. Bei gro\u00dfen Datenmengen oder nicht eindeutigen Clustern ben\u00f6tigen wir dann aber die Hilfe des Algorithmus.</p>", "a[href=\"#fig-kmeans-3-cluster-einfach-ergebnis\"]": "<figure class=\"align-center\" id=\"fig-kmeans-3-cluster-einfach-ergebnis\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_3_cluster_einfach_ergebnis.svg\"><img alt=\"../_images/kmeans_3_cluster_einfach_ergebnis.svg\" src=\"../_images/kmeans_3_cluster_einfach_ergebnis.svg\" style=\"width: 90%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.2 </span><span class=\"caption-text\">Ergebnis des k-Means-Clustering mit k=3</span><a class=\"headerlink\" href=\"#fig-kmeans-3-cluster-einfach-ergebnis\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#die-richtige-wahl-fur-k-mit-der-elbow-methode\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">23.7. </span>Die richtige Wahl f\u00fcr <span class=\"math notranslate nohighlight\">\\(k\\)</span> mit der Elbow-Methode<a class=\"headerlink\" href=\"#die-richtige-wahl-fur-k-mit-der-elbow-methode\" title=\"Link to this heading\">#</a></h2><p>Bisher haben wir f\u00fcr unsere Beispiele <span class=\"math notranslate nohighlight\">\\(k\\)</span> so gew\u00e4hlt, dass es dem Verst\u00e4ndnis passte. Doch in der Praxis stellt sich oft die Frage: <strong>Wie w\u00e4hle ich die optimale Anzahl von <span class=\"math notranslate nohighlight\">\\(k\\)</span> Clustern ?</strong></p><p>Hier kommt die <strong>Elbow-Methode</strong> ins Spiel. Sie hilft uns, auf systematische Weise die Anzahl der Cluster zu bestimmen, die sowohl eine gute Datenaufteilung gew\u00e4hrleistet als auch unn\u00f6tig viele Cluster vermeidet.</p>", "a[href=\"#fig-kmeans-obst\"]": "<figure class=\"align-center\" id=\"fig-kmeans-obst\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_obst.svg\"><img alt=\"../_images/kmeans_obst.svg\" src=\"../_images/kmeans_obst.svg\" style=\"width: 80%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.5 </span><span class=\"caption-text\">Obstsorten visualisiert nach Wassergehalt und Fruchzuckergehalt</span><a class=\"headerlink\" href=\"#fig-kmeans-obst\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"ki_allgemein.html#term-Manhattan-Distanz\"]": "<dt id=\"term-Manhattan-Distanz\">Manhattan-Distanz</dt><dd><p>Eine <a class=\"reference internal\" href=\"#term-Distanzmasze\"><span class=\"xref std std-term\">Distanzmetrik</span></a>, die die Summe der absoluten Differenzen zwischen den Koordinaten zweier Punkte berechnet. Beispiel: Die Manhattan-Distanz zwischen den Punkten (1, 2) und (4, 6) betr\u00e4gt <span class=\"math notranslate nohighlight\">\\(|1-4| + |2-6| = 7\\)</span>.</p></dd>", "a[href=\"#fig-kmeans-elbow-demo-svg\"]": "<figure class=\"align-center\" id=\"fig-kmeans-elbow-demo-svg\">\n<a class=\"reference internal image-reference\" href=\"../_images/kmeans_elbow_demo.svg\"><img alt=\"../_images/kmeans_elbow_demo.svg\" src=\"../_images/kmeans_elbow_demo.svg\" style=\"width: 90%;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Abb. 23.8 </span><span class=\"caption-text\">Demonstration der Elbow-Methode</span><a class=\"headerlink\" href=\"#fig-kmeans-elbow-demo-svg\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>"}
skip_classes = ["headerlink", "sd-stretched-link"]

window.onload = function () {
    for (const [select, tip_html] of Object.entries(selector_to_html)) {
        const links = document.querySelectorAll(`article.bd-article ${select}`);
        for (const link of links) {
            if (skip_classes.some(c => link.classList.contains(c))) {
                continue;
            }
            link.classList.add('has-tippy');
            tippy(link, {
                content: tip_html,
                allowHTML: true,
                arrow: false,
                placement: 'auto-start', maxWidth: 500, interactive: true, boundary: document.body, appendTo: document.body,
                onShow(instance) {MathJax.typesetPromise([instance.popper]).then(() => {var isFirefox=typeof InstallTrigger!=='undefined';if(isFirefox&&window.MathJax&&MathJax.startup&&MathJax.startup.output&&MathJax.startup.output.name==="SVG"){const svgs=instance.popper.querySelectorAll('svg');svgs.forEach(svg=>{let bbox=svg.getBBox(),x=bbox.x,y=bbox.y,width=bbox.width,height=bbox.height;svg.setAttribute('width',width);svg.setAttribute('height',height);svg.setAttribute('viewBox',`${x} ${y} ${width} ${height}`);});let rescale=0.015;svgs.forEach(svg=>{let bbox=svg.getBBox(),width=bbox.width,height=bbox.height;svg.setAttribute('width',width*rescale);svg.setAttribute('height',height*rescale);});}});},
            });
        };
    };
    console.log("tippy tips loaded!");
};

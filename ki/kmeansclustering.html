
<!DOCTYPE html>


<html lang="de" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>22. k-Means-Clustering &#8212; Datenstrukturen und KI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/thebe.css?v=9bca0c2f" />
    <link rel="stylesheet" type="text/css" href="../_static/code.css?v=4bf7ba55" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy_custom.css?v=eb815f20" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=91fba89f"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=79cc9f76"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script defer="defer" src="../_static/refresh.js?v=9bea9b76"></script>
    <script>const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script defer="defer" src="../_static/sphinx-thebe-lite.js?v=2a71eeb1"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script defer="defer" src="../_static/tippy/ki/kmeansclustering.17584432-39b5-4225-b559-4bb44cdb7a4f.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ki/kmeansclustering';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/dropdown-opener.js?v=628c8bad"></script>
    <link rel="canonical" href=" &#34;https://jil91.github.io/&#34;/ki/kmeansclustering.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Stichwortverzeichnis" href="../genindex.html" />
    <link rel="search" title="Suche" href="../search.html" />
    <link rel="next" title="22.8. Programmierung des Algorithmus" href="kmeansclustering2_aufgabe.html" />
    <link rel="prev" title="21.6. Eigenschaften und Varianten des k-Nächste-Nachbarn-Algorithmus" href="knearestneighbor2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="de"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Datenstrukturen und KI</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Suche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Nutzung</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../nutzung.html">1. Wie nutzt du dieses Buch am besten?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../live_code.html">1.3. Programmieren direkt in diesem Buch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../parsons_problems_einfuehrung.html">1.4. Parsons-Probleme</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Objektorienterte Programmierung (OOP)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../oop/t01_einstieg.html">2. Einführung in OOP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t02_kapselung.html">3. Datenkapselung</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t03_vererbung.html">4. Vererbung</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t05_interfaces.html">5. Interfaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t06_klassenvariablen.html">6. Klassenvariablen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t07_assoziationen.html">7. Assoziationen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t08_3SA.html">8. 3SA - Drei-Schichten-Architektur</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oop/t09_sequenzdiagramme.html">9. Sequenzdiagramme</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datenbanken</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../db/t10_einstieg_db.html">10. Einstieg Datenbanken</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t11_erm.html">11. Entity-Relationship-Modell (ERM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t12_erm_rm.html">12. Vom ERM ins Relationale Modell (RM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../db/t13_normalisierung.html">13. Normalisierung</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datenstrukturen</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/datenstrukturen_allgemein.html">14. Abstrakte Datentypen (ADT) vs Datenstrukturen</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/listen_einfuehrung.html">15. Listen</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_listen.html">15.2. Verkettete Listen</a></li>

<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen1.html">15.4. Operationen für verkettete Listen implementieren (Teil 1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen2.html">15.5. Operationen für verkettete Listen implementieren (Teil 2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/verkettete_liste_operationen_loesungen.html">15.6. Lösungen: Operationen für verkettete Listen implementieren</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/stapel_und_warteschlangen_intro.html">16. Stapel und Warteschlangen</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/stack.html">16.1. Stapel (Stack)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/stack-aufgaben.html">16.2. Übungen zu Stapeln</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/warteschlangen.html">16.3. Warteschlangen</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/assoziative_arrays.html">17. Assoziative Arrays</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datenstrukturen/baeume.html">18. Bäume</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/binaerbaeume.html">18.4. Binärbäume</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datenstrukturen/suchbaeume.html">18.5. Binäre Suchbäume</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datenstrukturen/klausurvorbereitung_mit_loesungen.html">19. Aufgaben zur Vorbereitung auf Klausur und Abitur</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Künstliche Intelligenz</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ki_allgemein.html">20. Künstliche Intelligenz: Einführung</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="knearestneighbor.html">21. Der k-Nächste-Nachbarn-Algorithmus</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="knearestneighbor2.html">21.6. Eigenschaften und Varianten des k-Nächste-Nachbarn-Algorithmus</a></li>

</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">22. k-Means-Clustering</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="kmeansclustering2_aufgabe.html">22.8. Programmierung des Algorithmus</a></li>
<li class="toctree-l2"><a class="reference internal" href="kmeansclustering2_loesung.html">22.9. Programmierung des Algorithmus (Lösung)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="entscheidungsbaumlernen.html">23. Entscheidungsbäume lernen</a></li>
<li class="toctree-l1"><a class="reference internal" href="minimax.html">24. Der Minimax-Algorithmus</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>



<a href="https://github.com/jil91/ds_ki-js2" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Quell-Repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Laden Sie diese Seite herunter">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/ki/kmeansclustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Quelldatei herunterladen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="In PDF drucken"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Vollbildmodus"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>k-Means-Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Inhalt </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uberwachtes-vs-unuberwachtes-lernen">22.1. Überwachtes vs. unüberwachtes Lernen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einfuhrung-in-das-verfahren">22.2. Einführung in das Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#der-k-means-clustering-algorithmus">22.3. Der k-means-Clustering Algorithmus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reale-anwendungsbeispiele">22.4. Reale Anwendungsbeispiele</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-konkretes-beispiel-clustering-von-obstsorten">22.5. Ein konkretes Beispiel: Clustering von Obstsorten</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisierung-der-clusterzentren-mit-kmeans">22.5.1. Initialisierung der Clusterzentren mit k‑means++</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-beispiel-zum-nachrechnen">22.6. Ein Beispiel zum Nachrechnen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode">22.7. Die richtige Wahl für <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="k-means-clustering">
<h1><span class="section-number">22. </span>k-Means-Clustering<a class="headerlink" href="#k-means-clustering" title="Link to this heading">#</a></h1>
<p>Du kennst bereits den <a class="reference internal" href="knearestneighbor.html"><span class="doc std std-doc">k-Nächste-Nachbarn-Algorithmus</span></a>, ein Verfahren, das mit <a class="reference internal" href="ki_allgemein.html#term-Trainingsdaten"><span class="xref std std-term">Trainingsdaten</span></a> neue Daten klassifiziert. Nun betrachten wir <a class="reference external" href="https://de.wikipedia.org/wiki/k-Means-Algorithmus">k-Means-Clustering</a>, einen Algorithmus, um <a class="reference internal" href="ki_allgemein.html#term-Datenpunkt"><span class="xref std std-term">Datenpunkte</span></a> in sogenannte Cluster zu gruppieren.</p>
<p>Im Bereich der KI wird oft mit großen Datenmengen gearbeitet, die auf Muster untersucht und in Gruppen eingeteilt werden. Algorithmen dieser Art sind Verfahren der <a class="reference external" href="https://de.wikipedia.org/wiki/Clusteranalyse">Clusteranalyse</a>. k-Means ist so ein Algorithmus, der Datenpunkte ohne vorherige Kenntnis der Gruppenzugehörigkeit in <span class="math notranslate nohighlight">\(k\)</span> Cluster einteilt. Das macht k-Means zu einem <a class="reference internal" href="ki_allgemein.html#term-Unuberwachtes-Lernen"><span class="xref std std-term">unüberwachten Lernalgorithmus</span></a>. Seine Stärke liegt in der effizienten Strukturierung großer Datensätze und dem Entdecken versteckter Muster.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="information admonition">
<p class="admonition-title">Info</p>
<p><a class="reference external" href="https://de.wikipedia.org/wiki/Maschinelles_Lernen">Maschinelles Lernen</a> ist ein Teilgebiet der KI, in dem Algorithmen aus Daten lernen und Vorhersagen oder Entscheidungen treffen können. Algorithmen im Bereich des maschinellen Lernens haben das Ziel, große Datenmengen zu analysieren und Muster darin zu erkennen.</p>
</div>
</aside>
<section id="uberwachtes-vs-unuberwachtes-lernen">
<h2><span class="section-number">22.1. </span>Überwachtes vs. unüberwachtes Lernen<a class="headerlink" href="#uberwachtes-vs-unuberwachtes-lernen" title="Link to this heading">#</a></h2>
<p>Beide Algorithmen stammen aus dem Bereich <strong>Maschinelles Lernen</strong>, welches grob in <strong>überwachtes Lernen</strong> und <strong>unüberwachtes Lernen</strong> unterteilt wird. Beim <a class="reference external" href="https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen">überwachten Lernen</a> wird ein Datensatz verwendet, der Trainingsdaten mit den zugehörigen <strong><a class="reference internal" href="ki_allgemein.html#term-Label"><span class="xref std std-term">Labels</span></a></strong> enthält. Das Modell lernt aus Beispielen, bei denen die richtigen Antworten bereits bekannt sind. Diese Methode eignet sich gut für Aufgaben wie Klassifikationen (z.B. Spam-Erkennung). Der <a class="reference internal" href="knearestneighbor.html"><span class="doc std std-doc">k-Nächste-Nachbarn-Algorithmus</span></a> ist ein solches Verfahren.</p>
<p>Beim <a class="reference external" href="https://de.wikipedia.org/wiki/Un%C3%BCberwachtes_Lernen">unüberwachten Lernen</a> sind die Trainingsdaten nicht gelabelt. Stattdessen versuchen unüberwachte Algorithmen, eigenständig Muster in den Daten zu erkennen. Clustering, wie k-Means, ist ein typisches Beispiel dafür. Der Algorithmus ermittelt Gruppen (Cluster) von ähnlichen Datenpunkten und hilft, ungeordnete Daten zu strukturieren.</p>
</section>
<section id="einfuhrung-in-das-verfahren">
<h2><span class="section-number">22.2. </span>Einführung in das Verfahren<a class="headerlink" href="#einfuhrung-in-das-verfahren" title="Link to this heading">#</a></h2>
<p>k-Means-Clustering gehört zum <strong>unüberwachten Lernen</strong>. Es gibt keine vordefinierten Labels, sondern nur die rohen Daten. Das Ziel von k-Means ist es, die Daten in <strong><span class="math notranslate nohighlight">\(k\)</span> Cluster</strong> zu unterteilen, wobei <span class="math notranslate nohighlight">\(k\)</span> die Anzahl der Cluster darstellt. Der Algorithmus ermittelt <strong>Zentroiden</strong>, auch Clusterzentren genannt. Das sind die Mittelpunkte, um die sich die Cluster bilden. <strong>Means</strong> steht dabei für den Durchschnitt, da die Zentroiden als Durchschnitt der zugehörigen Datenpunkte im Cluster berechnet werden. Am Ende sind die Daten innerhalb eines Clusters homogener als zu den Daten in anderen Clustern.</p>
<p>In einfachen Beispielen könnten wir die Cluster auch mit dem Auge erkennen und auch ablesen, welche Zahl für <span class="math notranslate nohighlight">\(k\)</span> sinnvoll wäre. Bei großen Datenmengen oder nicht eindeutigen Clustern benötigen wir dann aber die Hilfe des Algorithmus.</p>
<p><strong>Aufgabe 1:</strong> Wie würdest du denn die folgenden Daten in Cluster aufteilen?</p>
<figure class="align-center" id="fig-kmeans-3-cluster-einfach-datenpunkte">
<a class="reference internal image-reference" href="../_images/kmeans_3_cluster_einfach_datenpunkte.svg"><img alt="../_images/kmeans_3_cluster_einfach_datenpunkte.svg" src="../_images/kmeans_3_cluster_einfach_datenpunkte.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.1 </span><span class="caption-text">Beispiel von einfacher Verteilung von Datenpunkten</span><a class="headerlink" href="#fig-kmeans-3-cluster-einfach-datenpunkte" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip dropdown admonition">
<p class="admonition-title">Lösung</p>
<figure class="align-center" id="fig-kmeans-3-cluster-einfach-ergebnis">
<a class="reference internal image-reference" href="../_images/kmeans_3_cluster_einfach_ergebnis.svg"><img alt="../_images/kmeans_3_cluster_einfach_ergebnis.svg" src="../_images/kmeans_3_cluster_einfach_ergebnis.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.2 </span><span class="caption-text">Ergebnis des k-Means-Clustering mit k=3</span><a class="headerlink" href="#fig-kmeans-3-cluster-einfach-ergebnis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Es ist recht offensichtlich, dass die Datenpunkte in 3 Cluster aufgeteilt werden können.</p>
</div>
<p><strong>Aufgabe 2:</strong> Wenn du dir das nächste Beispiel anschaust: welche Cluster-Einteilung würdest du hier vornehmen?</p>
<figure class="align-center" id="fig-kmeans-3-cluster-komplex-datenpunkte">
<a class="reference internal image-reference" href="../_images/kmeans_4_cluster_komplex_datenpunkte.svg"><img alt="../_images/kmeans_4_cluster_komplex_datenpunkte.svg" src="../_images/kmeans_4_cluster_komplex_datenpunkte.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.3 </span><span class="caption-text">Beispiel von komplexer Verteilung von Datenpunkten</span><a class="headerlink" href="#fig-kmeans-3-cluster-komplex-datenpunkte" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip dropdown admonition">
<p class="admonition-title">Lösung</p>
<figure class="align-center" id="fig-kmeans-3-cluster-komplex-ergebnis">
<a class="reference internal image-reference" href="../_images/kmeans_4_cluster_komplex_ergebnis.svg"><img alt="../_images/kmeans_4_cluster_komplex_ergebnis.svg" src="../_images/kmeans_4_cluster_komplex_ergebnis.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.4 </span><span class="caption-text">Ergebnis des k-Means-Clustering mit k=4</span><a class="headerlink" href="#fig-kmeans-3-cluster-komplex-ergebnis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Dieses Beispiel ist nicht so trivial wie das vorige. Mit bloßem Auge lassen sich  die Cluster nicht ablesen.</p>
</div>
<p>Mit Hilfe des k-Means-Clustering können die Daten also sinnvoll unterteilt werden. Aber wie macht der Algorithmus das überhaupt? 🤔</p>
</section>
<section id="der-k-means-clustering-algorithmus">
<span id="k-means-clustering-algorithmus"></span><h2><span class="section-number">22.3. </span>Der k-means-Clustering Algorithmus<a class="headerlink" href="#der-k-means-clustering-algorithmus" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="seealso admonition">
<p class="admonition-title">Try it!</p>
<p>Auf <a class="reference external" href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering">dieser toll programmierten Seite</a> kann man den Algorithmus mit verschiedenen Datensammlugen graphisch nachspielen!</p>
</div>
</aside>
<p>Der Ablauf des k-means-Clustering Algorithmus wird in folgende Schritte aufgeteilt:</p>
<div class="admonition important" id="ablauf-k-means-algorithmus">
<p class="admonition-title">Wichtig</p>
<p><strong>Auswahl der Anzahl der Cluster (<span class="math notranslate nohighlight">\(k\)</span>)</strong><br />
Bevor der Algorithmus gestartet werden, muss die <strong>Anzahl der Cluster</strong> <span class="math notranslate nohighlight">\(k\)</span> festgelegt werden. Diese Zahl bestimmt, in wie viele Gruppen die Datenpunkte aufgeteilt werden sollen.</p>
<p><strong>1. Initialisierung der Zentroiden</strong><br />
Als nächstes werden <span class="math notranslate nohighlight">\(k\)</span> Datenpunkte aus den Daten oder <span class="math notranslate nohighlight">\(k\)</span> zufällige Punkte ausgewählt, um die anfänglichen <strong>Zentroiden</strong> (Cluster-Zentren) zu bestimmen.</p>
<p><strong>2. Zuweisung der Datenpunkte und Bildung der Cluster</strong><br />
Jeder Datenpunkt wird dem nächstgelegenen Zentroiden zugewiesen. Dies wird durch die <a class="reference internal" href="ki_allgemein.html#term-Distanzmasze"><span class="xref std std-term">Distanzmaße</span></a> zu allen Zentroiden bestimmt (z.B. mittels <a class="reference internal" href="ki_allgemein.html#term-Euklidische-Distanz"><span class="xref std std-term">Euklidischer Distanz</span></a> oder <a class="reference internal" href="ki_allgemein.html#term-Manhattan-Distanz"><span class="xref std std-term">Manhattan-Distanz</span></a>).</p>
<p><strong>3. Aktualisierung der Zentroiden</strong><br />
Die Zentroiden werden neu berechnet, indem der Durchschnitt (<strong>Mean</strong>) aller Punkte innerhalb eines Clusters berechnet wird.</p>
<p><strong>4. Wiederholung der Schritte 3 und 4</strong><br />
Die Schritte 2 und 3 werden solange wiederholt, bis sich die Zentroiden nicht mehr ändern oder eine maximale Anzahl an Iterationen erreicht ist.</p>
</div>
<p>Versuche mal zu überlegen, worin das Ziel des Algorithmus besteht? Denke dabei an die Beziehung der Datenpunkte <strong>innerhalb</strong> eines Clusters und Datenpunkte aus <strong>verschiedenen</strong> Clustern.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Lösung</p>
<p>Folgende Kriterien sind das Ziel:</p>
<ul class="simple">
<li><p>Die Ähnlichkeit der Datenpunkte <strong>innerhalb</strong> der einzelnen Cluster soll <strong>möglichst hoch</strong> sein.</p></li>
<li><p>Die Ähnlichkeit der Datenpunkte <strong>zwischen</strong> den einzelnen Clustern soll <strong>möglichst gering</strong> sein.</p></li>
</ul>
<p>Fazit: Die Datenpunkte <strong>innerhalb</strong> eines Cluster sollen eine <strong>höchstmögliche Homogenität</strong> haben.</p>
</div>
<p><strong>Frage:</strong> Warum benötigt es in der Regel mehrere Durchgänge (Iterationen), um die Cluster vollständig zu bilden?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Lösung</p>
<p>Der k-means Algorithmus braucht in der Regel mehrere Durchgänge, um die Cluster korrekt zu finden. Das liegt daran, dass die <strong>Zentroiden</strong> (also die Mittelpunkte der Cluster) anfangs <strong>zufällig gewählt</strong> werden. Am Anfang sind diese Zentroiden oft nicht optimal, da sie weit von den eigentlichen Clustern entfernt liegen können.</p>
<p>In jeder Iteration passiert Folgendes:</p>
<ol class="arabic simple">
<li><p>Jeder Datenpunkt wird dem nächstgelegenen Zentroiden zugewiesen, wodurch sich Cluster bilden oder auch ändern. Es ist gut möglich, dass ein Datenpunkt nun in einem anderen Cluster landet. Damit ändert sich dann wiederum auch die Position des Zentroiden.</p></li>
<li><p>Die Zentren werden dann neu berechnet, indem der Durchschnitt der Punkte in jeder Gruppe genommen wird.</p></li>
<li><p>Dieser Prozess wiederholt sich: Die Datenpunkte werden immer wieder neu zugeordnet, und die Zentren verschieben sich dabei nach und nach.</p></li>
</ol>
<p>Das Ziel ist, dass die Zentroiden eine Position erreichen, bei der sie sich gar nicht mehr oder nicht mehr groß bewegen, also eine <strong>stabile</strong> Lösung finden. Diese Stabilität wird auch <strong>Konvergenz</strong> genannt. Je nach Anfangslage der Zentroiden kann mehrere Interationen dauern, bis der Algorithmus eine stabile Gruppierung erreicht hat. Deshalb sind mehrere Iterationen nötig, um sicherzustellen, dass die Cluster gut und sinnvoll gebildet werden.</p>
<p>Dieses iterative Verfahren führt schließlich zu einer optimalen Gruppierung der Datenpunkte, wobei jeder Punkt in dem Cluster landet, das am besten zu seinen Eigenschaften passt.</p>
</div>
<p><strong>Hilfreiche Quellen fürs weitere Verständnis</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.maschinennah.de/ki-buch/">KI Buch: Wetterdaten-Beispiel</a></p></li>
<li><p><a class="reference external" href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">k-Means Clustering visualisiert </a></p></li>
<li><p><a class="reference external" href="https://shabal.in/visuals/kmeans/6.html">k-Means Clustering visualisiert mit Distanzenberechnug</a></p></li>
</ul>
</section>
<section id="reale-anwendungsbeispiele">
<h2><span class="section-number">22.4. </span>Reale Anwendungsbeispiele<a class="headerlink" href="#reale-anwendungsbeispiele" title="Link to this heading">#</a></h2>
<p>Welche realen Anwendungsbeispiele kannst du dir vorstellen, bei denen das k-means Clustering eingesetzt werden könnte?</p>
<p>Überlege dabei, in welchen Bereichen es wichtig sein könnte, Daten in Gruppen aufzuteilen, ohne dass bereits vorgegeben ist, zu welcher Gruppe ein Datenpunkt gehört. Welche Situationen kennst du, in denen Menschen, Dinge oder Objekte aufgrund ihrer Ähnlichkeit in Gruppen eingeteilt werden? Es gibt hier keine richtige Antwort, nur eine Auswahl an möglichen Einsatzszenarien.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Beispiele</p>
<ul class="simple">
<li><p><em>Marketing</em>: Kunden in verschiedene Segmente aufteilen. Dadurch können Unternehmen gezieltere Werbung schalten und ihre Produkte effizienter an die verschiedenen Kundengruppen anpassen.</p></li>
<li><p><em>Bildanalyse</em>: ähnliche Regionen in Bildern finden. Das ist besonders nützlich für die Objekterkennung. Hierbei hilft der Algorithmus, verschiedene Objekte in einem Bild zu identifizieren und zu klassifizieren.</p></li>
<li><p><em>Biologie</em>: Forscher nutzen den Algorithmus, um ähnliche Gene oder Spezies zu gruppieren. Dies kann helfen, neue Erkenntnisse über genetische Verbindungen und Unterschiede zu gewinnen und die Evolution besser zu verstehen.</p></li>
<li><p><em>Textanalyse</em>: Zum Beispiel kann der Algorithmus eingesetzt werden, um ähnliche Dokumente oder Artikel zu gruppieren, was bei der Organisation großer Textmengen hilfreich ist. In der Finanzwelt wird k-Means genutzt, um riskante von nicht riskanten Krediten zu unterscheiden, indem ähnliche Kreditprofile gruppiert werden.</p></li>
</ul>
</div>
</section>
<section id="ein-konkretes-beispiel-clustering-von-obstsorten">
<h2><span class="section-number">22.5. </span>Ein konkretes Beispiel: Clustering von Obstsorten<a class="headerlink" href="#ein-konkretes-beispiel-clustering-von-obstsorten" title="Link to this heading">#</a></h2>
<p>Wir möchten uns gesünder ernähren und wollen mehr Obst essen. Die WHO empfiehlt Obst mit hohen Fruchtzuckergehalt in geringen Maßen zu genießen. Obst mit einem hohen Wassergehalt führt zu einer höheren Sättigung. Nehmen wir an, wir haben Daten über Obstsorten mit Informationen wie u.a. Wassergehalt und Fruchtzuckergehalt. Wir möchten ähnliche Obstsorten in Clustern gruppieren, sodass die Obstsorten möglichst homogen sind. Anhand der Cluster können wir dann entscheiden, welches Obst wir in welchen Mengen essen können.</p>
<p>Wir spielen dieses Beispiel mal nach und schauen uns das Ergebnis an. Die zugeörigen Daten zu unseren Obstsorten sind:</p>
<small>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Obst</strong></p></th>
<th class="head text-left"><p><strong>Wassergehalt</strong></p></th>
<th class="head text-left"><p><strong>Fruchtzuckergehalt</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Apfel</p></td>
<td class="text-left"><p>85</p></td>
<td class="text-left"><p>10</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Birne</p></td>
<td class="text-left"><p>83</p></td>
<td class="text-left"><p>10</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Banane</p></td>
<td class="text-left"><p>75</p></td>
<td class="text-left"><p>12</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Orange</p></td>
<td class="text-left"><p>87</p></td>
<td class="text-left"><p>8</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Weintrauben</p></td>
<td class="text-left"><p>81</p></td>
<td class="text-left"><p>16</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Erdbeere</p></td>
<td class="text-left"><p>91</p></td>
<td class="text-left"><p>5</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Wassermelone</p></td>
<td class="text-left"><p>92</p></td>
<td class="text-left"><p>6</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Mango</p></td>
<td class="text-left"><p>83</p></td>
<td class="text-left"><p>14</p></td>
</tr>
</tbody>
</table>
</div>
</small><p>Keine übergroße Menge aber es ist schon mal nicht einfach, hier ad hoc eine konkrete Hilfestellung für unsere Obstfrage zu erhalten.</p>
<p>In <a class="reference internal" href="#fig-kmeans-obst"><span class="std std-numref">Abb. 22.5</span></a> ist die Sammlung von Obstsorten visualisiert: 🍎 (Apfel), 🍐 (Birne), 🍌 (Banane), 🍊 (Orange), 🍇 (Weintrauben), 🍓 (Erdbeere), 🍉 (Wassermelone), 🥭 (Mango). Wir möchten diese Obstsorten nun basierend auf Wasser- und Fruchtzuckergehalt in Cluster aufteilen.</p>
<figure class="align-center" id="fig-kmeans-obst">
<a class="reference internal image-reference" href="../_images/kmeans_obst.svg"><img alt="../_images/kmeans_obst.svg" src="../_images/kmeans_obst.svg" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.5 </span><span class="caption-text">Obstsorten visualisiert nach Wassergehalt und Fruchzuckergehalt</span><a class="headerlink" href="#fig-kmeans-obst" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Aufgabe 1:</strong> Wie würdest du die Obstsorten in Cluster aufteilen? Überlege dabei, wieviele Cluster sinnvoll wären, also welchen Wert <span class="math notranslate nohighlight">\(k\)</span> einnehmen würde.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Ergebnis k-Means</p>
<figure class="align-center" id="fig-kmeans-obst-3">
<a class="reference internal image-reference" href="../_images/kmeans_obst_clusters_3.svg"><img alt="../_images/kmeans_obst_clusters_3.svg" src="../_images/kmeans_obst_clusters_3.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.6 </span><span class="caption-text">k-Means-Clustering der Obstsorten mit k=3</span><a class="headerlink" href="#fig-kmeans-obst-3" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
<p><strong>Aufgabe 2:</strong> Versuche mal, das ermittelten Cluster in eigenen Worten zusammenzufassen.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Beschreibung des Ergebnisses</p>
<p>Der Algorithmus hat die Obstsorten in 3 Cluster aufgeteilt, deren Datenpunkte die folgenden Merkmale aufweisen:</p>
<ol class="arabic simple">
<li><p>🍌 (Banane), 🍇 (Weintrauben), 🥭 (Mango): <u>hoher bis sehr hoher</u> Fruchtzuckergehalt mit <u>mittlerem</u> Wassergehalt</p></li>
<li><p>🍎 (Apfel), 🍐 (Birne), 🍊 (Orange): <u>mittlerer</u> Fruchtzuckergehalt mit <u>hohem</u> Wassergehalt</p></li>
<li><p>🍓 (Erdbeere), 🍉 (Wassermelone): <u>niedriger</u> Fruchtzuckergehalt mit sehr <u>hohem</u> Wassergehalt</p></li>
</ol>
</div>
<p>Hast du die Einteilung von k-Means auch so überlegt oder hattest du eine andere Vorstellung? Was hälst du denn von dieser Einteilung im Vergleich zur vorigen Lösung?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Ergebnis k-Means Variante 2</p>
<figure class="align-center" id="fig-kmeans-obst-42">
<a class="reference internal image-reference" href="../_images/kmeans_obst_clusters_42.svg"><img alt="../_images/kmeans_obst_clusters_42.svg" src="../_images/kmeans_obst_clusters_42.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.7 </span><span class="caption-text">k-Means-Clustering der Obstsorten mit k=3 Variante 2</span><a class="headerlink" href="#fig-kmeans-obst-42" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
<p>Überlege mal einen Moment, wie der Algorithmus bei gleichen Daten zu diesen unterschiedlichen Ergebnisse kommen kann.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Tipp</p>
<p>Was könnte der <a class="reference internal" href="#ablauf-k-means-algorithmus"><span class="std std-ref">Algorithmus</span></a> zu Beginn anders gemacht haben, damit unterschiedliche Ergebnisse zustande kommen?</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Tipp, wenn du noch keine Idee hast</p>
<p>Wie werden die Zentroiden initialisiert und wie kann dieses Verfahrensweise zu unterschiedliche Ergebnissen führen?</p>
</div>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Lösung</p>
<p>Die unterschiedlichen Ergebnisse sind eine Folge davon, dass der Algorithmus mit zufälligen Startpunkten arbeitet. Je nachdem, wo die Zentroiden am Anfang liegen, teilt der Algorithmus die Punkte unterschiedlich ein. Das zeigt, dass k-Means manchmal unterschiedliche Ergebnisse liefern kann, auch wenn die Daten gleich bleiben.</p>
<ul class="simple">
<li><p>Wenn ein Start-Zentroid mitten in einer dichten Datenmenge liegt, zieht er schnell viele Punkte an.</p></li>
<li><p>Liegt ein anderer Start-Zentroid weit weg, wird er vielleicht nur wenige Punkte anziehen.
Der Algorithmus findet also nicht immer die ‘beste’ Lösung, sondern eine, die von den Startbedingungen abhängt</p></li>
</ul>
</div>
<section id="initialisierung-der-clusterzentren-mit-kmeans">
<h3><span class="section-number">22.5.1. </span>Initialisierung der Clusterzentren mit k‑means++<a class="headerlink" href="#initialisierung-der-clusterzentren-mit-kmeans" title="Link to this heading">#</a></h3>
<p><strong>[k-means++(<a class="reference external" href="https://de.wikipedia.org/wiki/K-Means-Algorithmus">https://de.wikipedia.org/wiki/K-Means-Algorithmus</a>)]</strong> ist eine verbesserte Methode zur Initialisierung der Clusterzentren beim k-means-Clustering. Es verbessert die Qualität und Effizienz des Algorithmus durch folgende Schritte:</p>
<ol class="arabic simple">
<li><p><strong>Erster Startpunkt</strong>:</p>
<ul class="simple">
<li><p>Ein Punkt wird zufällig aus den Daten gewählt.</p></li>
</ul>
</li>
<li><p><strong>Gewichtete Auswahl der weitere Startpunkte</strong>:</p>
<ul class="simple">
<li><p>Für jeden weiteren Startpunkt wird ein Punkt basierend auf seiner Distanz zu den nächsten bereits gewählten Startpunkten ausgewählt:</p>
<ul>
<li><p>Punkte, die weiter entfernt sind, haben eine höhere Wahrscheinlichkeit, ausgewählt zu werden.</p></li>
<li><p>Die Wahrscheinlichkeit ist proportional zum Quadrat der Distanz zum nächsten Startpunkt (<span class="math notranslate nohighlight">\(D^2\)</span>).</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Wiederhole Schritt 2</strong>, bis <span class="math notranslate nohighlight">\(k\)</span> Startpunkte bestimmt sind.</p></li>
<li><p><strong>Führe anschließend das normale k-means-Verfahren durch</strong>.</p></li>
</ol>
<p><strong>Vorteil:</strong> Die Startpunkte werden optimal verteilt, was zu schnellerer Konvergenz und besseren Clustering-Ergebnissen führt.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Wie funktioniert die gewichtete Auswahl genau?</strong></p>
<p>Angenommen, es gibt 5 Punkte mit diesen Distanzen zu den bestehenden Zentren:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Punkt</p></th>
<th class="head"><p>Entfernung <span class="math notranslate nohighlight">\(D\)</span></p></th>
<th class="head"><p>Gewicht <span class="math notranslate nohighlight">\(D^2\)</span></p></th>
<th class="head"><p>Wahrscheinlichkeit</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(A\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1^2 = 1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1 / (1 + 9 + 25 + 36 + 64) = 1/135 \approx 0.74\%\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(B\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3^2 = 9\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(9 / 135 \approx 6.67\%\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(C\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(5\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(5^2 = 25\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(25 / 135 \approx 18.52\%\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(D\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(6\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(6^2 = 36\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(36 / 135 \approx 26.67\%\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(E\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(8\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(8^2 = 64\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(64 / 135 \approx 47.41\%\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div style="margin-top: 20px;"></div>
<p>Punkt <span class="math notranslate nohighlight">\(E\)</span> hat die größte Wahrscheinlichkeit, gewählt zu werden, aber nicht zu 100%. Es kann jedoch auch jeder andere Punkt gewählt werden, abhängig von seiner Wahrscheinlichkeit.</p>
</div>
</section>
</section>
<section id="ein-beispiel-zum-nachrechnen">
<h2><span class="section-number">22.6. </span>Ein Beispiel zum Nachrechnen<a class="headerlink" href="#ein-beispiel-zum-nachrechnen" title="Link to this heading">#</a></h2>
<p>Du weißt nun, wie der Algorithmus funktioniert und zu welchen Ergebnissen er führen kann. Am besten kannst du das nachvollziehen, indem du den Algorithmus selbst mal durchführst. Lade dir dieses
<a class="reference download internal" download="" href="../_downloads/2d91cf82f12585d06b6443a793bb352d/kmeansclustering_aufgabenblatt.pdf"><code class="xref download docutils literal notranslate"><span class="pre">Aufgabenblatt</span></code></a> herunter und bearbeite es. Die Anweisungen findest du dem Arbeitsblatt. Viel Erfolg 💪</p>
</section>
<section id="die-richtige-wahl-fur-k-mit-der-elbow-methode">
<h2><span class="section-number">22.7. </span>Die richtige Wahl für <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode<a class="headerlink" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode" title="Link to this heading">#</a></h2>
<p>Bisher haben wir für unsere Beispiele <span class="math notranslate nohighlight">\(k\)</span> so gewählt, dass es dem Verständnis passte. Doch in der Praxis stellt sich oft die Frage: <strong>Wie wähle ich die optimale Anzahl von <span class="math notranslate nohighlight">\(k\)</span> Clustern ?</strong></p>
<p>Hier kommt die <strong>Elbow-Methode</strong> ins Spiel. Sie hilft uns, auf systematische Weise die Anzahl der Cluster zu bestimmen, die sowohl eine gute Datenaufteilung gewährleistet als auch unnötig viele Cluster vermeidet.</p>
<p>Die Idee der Methode ist wie folgt:</p>
<ul class="simple">
<li><p>Wir berechnen die sogenannte <strong>Trägheit</strong> (Summe der Abstände der Datenpunkte zu ihren Clusterzentren) für verschiedene Werte von <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
<li><p>Die Trägheit nimmt mit steigender Clusteranzahl <span class="math notranslate nohighlight">\(k\)</span> ab, weil mehr Cluster zu kleineren Distanzen führen.</p></li>
<li><p>Jedoch flacht die Abnahme ab, und ab einem bestimmten Punkt lohnt es sich nicht mehr, die Anzahl der Cluster weiter zu erhöhen. Dieser Punkt wird als <strong>Knickpunkt (Elbow)</strong> bezeichnet.</p></li>
</ul>
<figure class="align-center" id="fig-kmeans-elbow-demo-svg">
<a class="reference internal image-reference" href="../_images/kmeans_elbow_demo.svg"><img alt="../_images/kmeans_elbow_demo.svg" src="../_images/kmeans_elbow_demo.svg" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Abb. 22.8 </span><span class="caption-text">Demonstration der Elbow-Methode</span><a class="headerlink" href="#fig-kmeans-elbow-demo-svg" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Die optimale Anzahl der Cluster <span class="math notranslate nohighlight">\(k\)</span> ist genau dort, wo dieser Knickpunkt liegt. Dies ist der Punkt, an dem die Verbesserung durch mehr Cluster stark nachlässt, und wir eine gute Balance zwischen Genauigkeit und Einfachheit erreichen.</p>
<div class="note admonition">
<p class="admonition-title">Warum funktioniert die Elbow-Methode?</p>
<p>Die Methode basiert auf der Idee, dass eine kleine Anzahl von Clustern zu einer schlechten Gruppierung führt, während eine zu große Anzahl von Clustern unnötig ist und zu <a class="reference internal" href="#overfitting"><span class="xref myst">Overfitting</span></a> führen kann. Der Knick bei Anzahl der Cluster <span class="math notranslate nohighlight">\(= 2\)</span> zeigt den Punkt, an dem sich der Aufwand für mehr Cluster nicht mehr lohnt.</p>
</div>
<p>Mit der Elbow-Methode können wir also datengetrieben und anschaulich entscheiden, wie viele Cluster sinnvoll sind, anstatt dies nur durch Intuition oder Versuch und Irrtum zu bestimmen.</p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

        <script type="text/x-thebe-config">
        {
            "rootPath": "..",
            "requestKernel": true,
            "useJupyterLite": true,
            "useBinder": false,
            "kernelOptions": {
                "path": "/"
            },
            "codeMirrorConfig": {
                "theme": "default",
                "mode": "python"
            },
            "mountRestartButton": false,
            "mountRestartallButton": false
        }
        </script>
        <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="knearestneighbor2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">zurück</p>
        <p class="prev-next-title"><span class="section-number">21.6. </span>Eigenschaften und Varianten des k-Nächste-Nachbarn-Algorithmus</p>
      </div>
    </a>
    <a class="right-next"
       href="kmeansclustering2_aufgabe.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title"><span class="section-number">22.8. </span>Programmierung des Algorithmus</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Inhalt
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uberwachtes-vs-unuberwachtes-lernen">22.1. Überwachtes vs. unüberwachtes Lernen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einfuhrung-in-das-verfahren">22.2. Einführung in das Verfahren</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#der-k-means-clustering-algorithmus">22.3. Der k-means-Clustering Algorithmus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reale-anwendungsbeispiele">22.4. Reale Anwendungsbeispiele</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-konkretes-beispiel-clustering-von-obstsorten">22.5. Ein konkretes Beispiel: Clustering von Obstsorten</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisierung-der-clusterzentren-mit-kmeans">22.5.1. Initialisierung der Clusterzentren mit k‑means++</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ein-beispiel-zum-nachrechnen">22.6. Ein Beispiel zum Nachrechnen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#die-richtige-wahl-fur-k-mit-der-elbow-methode">22.7. Die richtige Wahl für <span class="math notranslate nohighlight">\(k\)</span> mit der Elbow-Methode</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Durch Michael Brenner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>